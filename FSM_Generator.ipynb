{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "645f187c-38e6-479d-8caa-b7a559aa7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _collections_abc import Sequence, Iterable\n",
    "from abc import ABC\n",
    "from sage.combinat.finite_state_machine import FiniteStateMachine, FSMState, FSMTransition, Automaton\n",
    "from sage.combinat.subset import powerset\n",
    "import matplotlib\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6461bfd-4f54-46ac-a240-a9b543625342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordGenerator:\n",
    "    def __init__(self, commutation_dict: dict[str: list], order_dict: dict[str: int]):\n",
    "        self.c_map = commutation_dict\n",
    "        self.o_map = order_dict\n",
    "\n",
    "    def word(self, word):\n",
    "        return Word(word, self.c_map, self.o_map)\n",
    "\n",
    "    def horocyclic_word(self, subwordlist, mode):\n",
    "        return HorocyclicWord(subwordlist, mode, self.c_map, self.o_map)\n",
    "\n",
    "\n",
    "class Word(Sequence):\n",
    "    def __init__(self, word, commutation_dict: dict[str: list], order_dict: dict[str: int]):\n",
    "        if word is list:\n",
    "            self.word_as_list = word\n",
    "        elif isinstance(word, Iterable):\n",
    "            self.word_as_list = list(word)\n",
    "        else:\n",
    "            raise TypeError(\"argument 'word' is not iterable\")\n",
    "        self.c_map = commutation_dict\n",
    "        self.o_map = order_dict\n",
    "        self.alphabet = set().union(letter for letter in order_dict)\n",
    "        # super.__init__()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.word_as_list[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_as_list)\n",
    "\n",
    "    def __str__(self):\n",
    "        return ''.join(str(a) for a in self.word_as_list)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Word):\n",
    "            return self.word_as_list == other.word_as_list\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return('Word(' + str(self.word_as_list) +')')\n",
    "\n",
    "    def word_as_tuple (self) -> tuple:\n",
    "        return (tuple(self.word_as_list))\n",
    "    \n",
    "    def copy(self):\n",
    "        copy_word_list = list(letter for letter in self.word_as_list)\n",
    "        return Word(copy_word_list, self.c_map, self.o_map)\n",
    "\n",
    "    def append(self, value: str) -> None:\n",
    "        self.word_as_list.append(value)\n",
    "\n",
    "    def shortlex_append(self, value: str):\n",
    "        optimal_insert_idx = len(self.word_as_list)\n",
    "        for i in reversed(range(len(self.word_as_list))):\n",
    "            if value not in self.c_map[self.word_as_list[i]]:\n",
    "                break\n",
    "            if self.o_map[self.word_as_list[i]] > self.o_map[value]:\n",
    "                optimal_insert_idx = i\n",
    "        self.word_as_list.insert(optimal_insert_idx, value)\n",
    "        return self\n",
    "\n",
    "    def insert(self, index: int, value: str):\n",
    "        self.word_as_list.insert(index, value)\n",
    "        return self\n",
    "\n",
    "    def __neighborhood(self, letter: str) -> set:\n",
    "        return set(self.c_map[letter])\n",
    "\n",
    "class HorocyclicWord(Sequence):\n",
    "    def __init__(self, subword_list:list, mode:bool, commutation_dict: dict[str: list], order_dict: dict[str: int]):\n",
    "        '''\n",
    "        :param subwordlist: a list of 4 lists. Each inner list should be a list of strings.\n",
    "        :param mode: True if the word is of form 1234, False if the word is of form 1256. Note that the class will not check that the word is of the desired form.\n",
    "        '''\n",
    "        if len(subword_list) != 4:\n",
    "            raise ValueError ('Please specify exactly 4 (possibly empty) subwords')\n",
    "\n",
    "        self.c_map = commutation_dict\n",
    "        self.o_map = order_dict\n",
    "        self.alphabet = set().union(letter for letter in order_dict)\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.SubwordList = subword_list \n",
    "        self.final_subword = 0\n",
    "        for i in reversed(range (0, 4)):\n",
    "            if subword_list[i] != []:\n",
    "                self.final_subword = i\n",
    "                break\n",
    "\n",
    "        self.word_as_list = subword_list[0]+subword_list[1]+subword_list[2]+subword_list[3]\n",
    "                \n",
    "    def __getitem__(self, item):\n",
    "        return self.SubwordList[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_as_list)\n",
    "\n",
    "    def __str__(self):\n",
    "        return ''.join(str(a) for a in self.word_as_list)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, HorocyclicWord):\n",
    "            return self.SubwordList == other.SubwordList\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return('HorocyclicWord(' + self.SubwordList +')')\n",
    "    \n",
    "    def copy(self):\n",
    "        copy_subword_list = [list(letter for letter in self.SubwordList[0]), list(letter for letter in self.SubwordList[1]), list(letter for letter in self.SubwordList[2]), list(letter for letter in self.SubwordList[3])]\n",
    "        return HorocyclicWord(copy_subword_list, self.mode, self.c_map, self.o_map)\n",
    "    \n",
    "    def append(self, letter: str, position: int) -> None:\n",
    "        if self.final_subword > position:\n",
    "            raise ValueError ('cannot append to subwords which have ended')\n",
    "        self.SubwordList[position].append(letter)\n",
    "        self.word_as_list.append(letter)\n",
    "        self.final_subword = position\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d2d5e80-4b01-4eef-a480-ff067199a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not used in the below. Keeping around only in case it's needed.\n",
    "\n",
    "def multi_epsilon_successors(concatenated_machine: Automaton, start_state: FSMState) -> list[FSMTransition]:\n",
    "        '''\n",
    "        Given an input automaton and a state in that automaton, this function gives a list of composite transitions that arise as a (possibly empty) sequence of epsilon transitions followed by one non-epsilon transition.\n",
    "\n",
    "        :param concatenated_machine: an automaton with epsilon states. If there are epsilon loops this might not work, but should at least terminate.\n",
    "        :param start_state: a state in concatenated_machine whose successors we would like.\n",
    "\n",
    "        :return: a list of FSMTransitions from start_state to end_state, where end_state can be reached from start_state by a sequence of epsilon transitions followed by a single non-epsilon transition.\n",
    "        The list entries are labeled by the labels of their non-epsilon transitions.\n",
    "        '''\n",
    "\n",
    "        MultiEpsilonTransitionList = []\n",
    "        \n",
    "        if not start_state in concatenated_machine.states():\n",
    "            raise ValueError (\"The starting state does not appear in the provided automaton\")\n",
    "\n",
    "        for epsilon_successor_state in set(concatenated_machine.epsilon_successors(start_state).keys()).union({start_state}):\n",
    "            for non_epsilon_transition in concatenated_machine.transitions(concatenated_machine.state(epsilon_successor_state)):\n",
    "                if non_epsilon_transition.word_in == []:\n",
    "                    continue\n",
    "                MultiEpsilonTransitionList.append(FSMTransition(start_state, non_epsilon_transition.to_state, non_epsilon_transition.word_in))\n",
    "        \n",
    "        #print('Total non-epsilon trasitions are')\n",
    "        #print(MultiEpsilonTransitionList)\n",
    "        return MultiEpsilonTransitionList\n",
    "    \n",
    "def de_epsilonize(concatenated_machine: Automaton) ->Automaton:\n",
    "        '''\n",
    "        Unfortunately, sage.combinat.finite_sate_machine.FiniteStateMachine.concatenation relies on the creation of epsilon-transitions, which means that intersections of concatenated languages are not well-defined.\n",
    "        Therefore, to make the language of horocyclic suffices, we will use this function that deletes epsilon transitions.\n",
    "        This uses the fact that the beginning of each word w_i is unambiguous, since w_{i+1} always begins with a letter that was not alowed to be in w_i. Do not use this function if this is not the case. \n",
    "        (An alternative implementation involves constructing a nondeterministic concatenation machine and then determinizing it. This is more work).\n",
    "        \n",
    "        :param concatenated_machine: an Automaton with some number of epsilon transitions.\n",
    "        \n",
    "        :return: an Automaton which accepts the same language as concatenated_machine, without epsilon transitions.\n",
    "        This may not be deterministic. If it is a concatenation of other machines with languages L_1, ...L_k such that words in L_i never end with letters that words in L_{i+1} begin with, then it will be deterministic.\n",
    "        \n",
    "        '''\n",
    "        TransitionList = []\n",
    "        FinishedStates = []\n",
    "        Frontier = []\n",
    "        \n",
    "        for StartingState in concatenated_machine.initial_states():\n",
    "            NewTransitions = multi_epsilon_successors(concatenated_machine, StartingState)\n",
    "            for new_transition in NewTransitions:\n",
    "                Frontier.append(new_transition.to_state)\n",
    "            TransitionList.extend(NewTransitions)\n",
    "            FinishedStates.append(StartingState)\n",
    "\n",
    "        while len(Frontier)>0:\n",
    "            SourceState = Frontier.pop(0)\n",
    "\n",
    "            # We have already considered source and all its outgoing edges, we can skip it\n",
    "            if SourceState in FinishedStates:\n",
    "                continue\n",
    "            NewTransitions = multi_epsilon_successors(concatenated_machine, SourceState)\n",
    "            for new_transition in NewTransitions:\n",
    "                Frontier.append(new_transition.to_state)\n",
    "            TransitionList.extend(NewTransitions)\n",
    "            FinishedStates.append(SourceState)\n",
    "\n",
    "        #print('de-epsilonized TransitionList is')\n",
    "        #print(TransitionList)\n",
    "    \n",
    "        return Automaton(TransitionList)\n",
    "        \n",
    "def unambiguous_concatenation(first_machine: Automaton, second_machine: Automaton) -> Automaton:\n",
    "    '''\n",
    "    A custom concatenation function for automata M_1, M_2 with languages L_1 and L_2, satisfying the following:\n",
    "    (1) M_1 and M_2 have no epsilon transitions\n",
    "    (2) No word of L_1 ends with a letter that a word of L_2 begins with.\n",
    "    (3) L_2 contains the empty word.\n",
    "    The code is a modification of the .concatenation(other) method from sage.combinat.finite_state_machine.\n",
    "    If (2) is not satisfied, this should output a non-deterministic automaton recognizing L_1L_2\n",
    "    \n",
    "    :param first_machine: a non-empty Automaton recognizing the language L_1\n",
    "    :param second_machine: a non-empty Automaton recognizing the language L_2\n",
    "\n",
    "    :return: an automaton without epsilon transitions recognizing the concatenated language L_1L_2\n",
    "    '''\n",
    "        \n",
    "    result = self.empty_copy()\n",
    "    first_states = {}\n",
    "    second_states = {}\n",
    "    for s in first_machine.iter_states():\n",
    "        new_state = s.relabeled((0, s.label()))\n",
    "        first_states[s] = new_state\n",
    "        result.add_state(new_state)\n",
    "        #Unlike in sage.combinat.finite_state_machine, we allow these states to be final exactly when the state they are copying is final. This means that each word w_1 in L_1 will again be accepted by the result, without needing an epsilon transition to a starting state of M_2\n",
    "\n",
    "    \n",
    "    for s in second_machine.iter_states():\n",
    "        new_state = s.relabeled((1, s.label()))\n",
    "        new_state.is_initial = False\n",
    "        second_states[s] = new_state\n",
    "        result.add_state(new_state)\n",
    "\n",
    "    for t in first_machine.iter_transitions():\n",
    "        result.add_transition(first_states[t.from_state],\n",
    "                              first_states[t.to_state],\n",
    "                              t.word_in,\n",
    "                              t.word_out)\n",
    "\n",
    "    for t in second_machine.iter_transitions():\n",
    "        result.add_transition(second_states[t.from_state],\n",
    "                              second_states[t.to_state],\n",
    "                              t.word_in,\n",
    "                              t.word_out)\n",
    "\n",
    "    for s in first_machine.iter_final_states():\n",
    "        first_state = first_states[s]\n",
    "        for t in second_machine.iter_initial_states():\n",
    "            second_state = second_states[t]\n",
    "            #Unlike in sage.combinat.finite_state_machine, we create labeled transitions directly to those states in second_machine that immediately follow initial states. This avoids the creation of epsilon transitions.\n",
    "            for transition in second_machine.transitions(second_state):\n",
    "                result.add_transition(first_state,\n",
    "                                      transition.to_state,\n",
    "                                      transition.word_in,\n",
    "                                      transition.word_out)\n",
    "        try:\n",
    "            result.input_alphabet = list(set(self.input_alphabet)\n",
    "                                         | set(other.input_alphabet))\n",
    "        except TypeError:\n",
    "            # e.g. None or unhashable letters\n",
    "            result.input_alphabet = None\n",
    "\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d73728e-3ffd-4563-aebf-94224f01d80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    Commented out for now. It appears to be correct, but it was giving an unhashable type error, which suggests that some transitions are not labeled as intended.\\n    \\n    def transition_dict(self, state:FSMState) -> dict:\\n        '''\\n        Generate a dictionary describing the FSMTransitions of self that start at the provided state.\\n        Keys to this dictionary are letters of the input alphabet, and values are instances of FSMtransition starting at state and labeled by the key value.\\n        \\n        :param state: a state in self.\\n        :return: A dictionary whose keys are the letters of the input alphabet and whose values are the transitions from state labeled by those keys.\\n        '''\\n\\n        if not self.is_deterministic:\\n            raise ValueError('Not implemented for non-deterministic automata')\\n            \\n        TransitionDict = {}\\n        for transition in self.iter_transitions(state):\\n            TransitionDict[transition.word_in]=transition\\n        return TransitionDict\\n\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConcatableAutomaton(Automaton):\n",
    "    #This is the class for the automata we will use in this paper.\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        This is the initialization statement copied for automata\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def unambiguous_concatenation(self, other: 'ConcatableAutomaton') -> 'ConcatableAutomaton':\n",
    "        '''\n",
    "        A custom concatenation function for ConcatableAutomata M_1, M_2 with languages L_1 and L_2, satisfying the following:\n",
    "        (1) M_1 and M_2 have no epsilon transitions\n",
    "        (2) No word of L_1 ends with a letter that a word of L_2 begins with.\n",
    "        (3) L_2 contains the empty word.\n",
    "        The code is a modification of the .concatenation(other) method from sage.combinat.finite_state_machine.\n",
    "        If (2) is not satisfied, this should output a non-deterministic automaton recognizing L_1L_2\n",
    "    \n",
    "        :param other: a non-empty Concatable Automaton.\n",
    "\n",
    "        :return: a ConcatableAutomaton without epsilon transitions recognizing the concatenated language L_1L_2\n",
    "        '''\n",
    "\n",
    "        TransitionList = []\n",
    "        first_states = {}\n",
    "        second_states = {}\n",
    "        for s in self.iter_states():\n",
    "            new_state = s.relabeled((0, s.label()))\n",
    "            first_states[s] = new_state\n",
    "            #Unlike in sage.combinat.finite_state_machine, we allow these states to be final when the state they are copying is final. This means that each word w_1 in L_1 will again be accepted by the result, without needing an epsilon transition to a starting state of M_2\n",
    "\n",
    "    \n",
    "        for s in other.iter_states():\n",
    "            new_state = s.relabeled((1, s.label()))\n",
    "            new_state.is_initial = False\n",
    "            second_states[s] = new_state\n",
    "\n",
    "        for t in self.iter_transitions():\n",
    "            NewTransition = FSMTransition(first_states[t.from_state],\n",
    "                                          first_states[t.to_state],\n",
    "                                          t.word_in,\n",
    "                                          t.word_out)\n",
    "            TransitionList.append(NewTransition)\n",
    "\n",
    "        for t in other.iter_transitions():\n",
    "            if (t.from_state).is_initial:\n",
    "                continue\n",
    "            NewTransition = FSMTransition(second_states[t.from_state],\n",
    "                                          second_states[t.to_state],\n",
    "                                          t.word_in,\n",
    "                                          t.word_out)\n",
    "            TransitionList.append(NewTransition)\n",
    "\n",
    "        for s in self.iter_final_states():\n",
    "            first_state = first_states[s]\n",
    "            for t in other.iter_initial_states():\n",
    "                second_state = second_states[t]\n",
    "                #Unlike in sage.combinat.finite_state_machine, we create labeled transitions directly to those states in other that immediately follow initial states. This avoids the creation of epsilon transitions.\n",
    "                for transition in other.transitions(t):\n",
    "                    NewTransition = FSMTransition (first_state,\n",
    "                                                   second_states[transition.to_state],\n",
    "                                                   transition.word_in,\n",
    "                                                   transition.word_out)\n",
    "                    TransitionList.append(NewTransition)\n",
    "   \n",
    "        return ConcatableAutomaton(TransitionList)\n",
    "\n",
    "    def concatable_intersection(self, other: 'ConcatableAutomaton', only_accessible_components = True) -> 'ConcatableAutomaton':\n",
    "        #Compute self.intersection(other) as in sage.combinat.finite_state_machine, but return ConcatableAutomaton\n",
    "\n",
    "        return ConcatableAutomaton(self.intersection(other, only_accessible_components))\n",
    "    \n",
    "    def _interspersal(self, other: 'ConcatableAutomaton') -> 'ConcatableAutomaton':\n",
    "        '''Let the languages L_0 and L_1 be recognized respectively by self and other. This method takes the union of the even-length words in L_0 and the odd-length words in L_1\n",
    "        \n",
    "        :param self: A ConcatableAutomaton.\n",
    "        :param other: A ConcatableAutomaton.\n",
    "\n",
    "        :return: A ConcatableAutomaton recognizing the even-length words accepted by self and the odd length words accepted by other.     \n",
    "        '''\n",
    "        \n",
    "        self.input_alphabet = set(self.input_alphabet).union(set(other.input_alphabet))\n",
    "        other.input_alphabet = set(self.input_alphabet).union(set(other.input_alphabet))\n",
    "        \n",
    "        CompleteSelf = self.completion()\n",
    "        CompleteOther = other.completion()\n",
    "        \n",
    "        #Define an automaton to keep track of the parity of the lengths of words.\n",
    "        \n",
    "        EvenState = FSMState(0, is_initial = True, is_final = True)\n",
    "        OddState = FSMState(1, is_initial = False, is_final = True)\n",
    "        TransitionList = []\n",
    "        for letter in set(self.input_alphabet).union(set(other.input_alphabet)):\n",
    "            TransitionList.append(FSMTransition(EvenState, OddState, letter))\n",
    "            TransitionList.append(FSMTransition(OddState, EvenState, letter))\n",
    "        ParityMachine = ConcatableAutomaton(TransitionList)\n",
    "        \n",
    "        ApproxMachine = ParityMachine.concatable_intersection(CompleteSelf.concatable_intersection(CompleteOther))\n",
    "        #Because all these machines are complete, self.concatable_intersection(other) will still track its progress in other of a word rejected by self, and vice versa.\n",
    "        #States (n, (self.state(spam), other.state(spam))) are final iff both (self.state(spam)) and (other.state(spam)) are, where n is either EvenState or OddState. So this automaton has the correct states but no final states.\n",
    "        \n",
    "        for state in ApproxMachine.iter_states():\n",
    "            #Labels are of the form (n, (self.state(spam), other.state(spam))). We need n.label() to get the parity. \n",
    "            parity = (state.label()[0]).label()\n",
    "            state.is_final = state.label()[1].label()[parity].is_final\n",
    "\n",
    "        return ApproxMachine\n",
    "\n",
    "\"\"\"\n",
    "    Commented out for now. It appears to be correct, but it was giving an unhashable type error, which suggests that some transitions are not labeled as intended.\n",
    "    \n",
    "    def transition_dict(self, state:FSMState) -> dict:\n",
    "        '''\n",
    "        Generate a dictionary describing the FSMTransitions of self that start at the provided state.\n",
    "        Keys to this dictionary are letters of the input alphabet, and values are instances of FSMtransition starting at state and labeled by the key value.\n",
    "        \n",
    "        :param state: a state in self.\n",
    "        :return: A dictionary whose keys are the letters of the input alphabet and whose values are the transitions from state labeled by those keys.\n",
    "        '''\n",
    "\n",
    "        if not self.is_deterministic:\n",
    "            raise ValueError('Not implemented for non-deterministic automata')\n",
    "            \n",
    "        TransitionDict = {}\n",
    "        for transition in self.iter_transitions(state):\n",
    "            TransitionDict[transition.word_in]=transition\n",
    "        return TransitionDict\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ede98f3f-4c21-49ee-bba8-474bbc6ad8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rips_FSM_Generator:\n",
    "    def __init__(self, commutation_dict:dict[str, set], order_dict: dict[str, int], ray: list[str]):\n",
    "        \n",
    "        '''\n",
    "        This object will make the necessary automata for the Rips graph on a horosphere.\n",
    "    \n",
    "        :param commutation_dict: A dictionary representation of a defining graph. A letter (key) is associated with a list of letters (value) that the key letter commutes with. This list should not include the key letter.\n",
    "        Note: this program does not check that commutation_dict is symmetrical. You need to make sure that if your input allows a_i to commute with a_j, then a_j is also allowed to commute with a_i.\n",
    "        :param order_dict: A dictionary representation of a total ordering on the letter in the defining graph. A letter (key) is associated with an index (value) that represents that letters relative position in the ordering.\n",
    "        :param ray: A list of two characters that will be used to generate the chosen ray to infinity. In the paper these are referred to as a_i and a_j respectively.\n",
    "        '''\n",
    "\n",
    "        if not len(ray) == 2:\n",
    "            raise ValueError (\"The defining ray should have two letters\")\n",
    "        elif ray [1] in commutation_dict[ray[0]]:\n",
    "            raise ValueError (\"The defining ray consists of two letters which commute\")\n",
    "        \n",
    "        self.c_map = commutation_dict\n",
    "        self.o_map = order_dict\n",
    "        self.alphabet = set().union(letter for letter in self.o_map)\n",
    "        self.ray = ray\n",
    "\n",
    "        StringOfAllLetters = ''.join(letter for letter in self.alphabet)\n",
    "        if '-' in StringOfAllLetters:\n",
    "            raise ValueError ('''The character '-' is reserved to be the blank character''')\n",
    "        if ',' in StringOfAllLetters:\n",
    "            raise ValueError('''The character ',' is reserved for delimiting lists''')\n",
    "        if '_' in StringOfAllLetters:\n",
    "            raise ValueError(''' The character '_' is reserved for the word breaks in horocyclic suffices''')\n",
    "        \n",
    "        #the lesser_star dictionary agrees with the function Star_< in the paper. When passed a key of a letter, it returns the set of letters that commute with and precede the key. Note the strict inequality.\n",
    "        self.lesser_star = {}\n",
    "        for letter in self.alphabet:\n",
    "            LesserStarOfLetter = set(filter(lambda x: self.o_map[x] < self.o_map[letter], self.c_map[letter]))\n",
    "            self.lesser_star[letter] = LesserStarOfLetter\n",
    "        self.greater_star = {}\n",
    "        for letter in self.alphabet:\n",
    "            self.greater_star[letter] = self.c_map[letter].difference(self.lesser_star[letter])\n",
    "\n",
    "    \n",
    "    def __first_letter_excluder(self, excluded_letters:set) -> ConcatableAutomaton:\n",
    "        '''\n",
    "        Generate an FSM that prevents a chosen set of letters from reaching the beginning of the word without cancellation. The states in this machine represent which letters could still reach the beginning of the word.\n",
    "        \n",
    "        :param excluded_letters: A set of letters which that accepted words should not begin with.\n",
    "                \n",
    "        :return: An automaton that accepts words which, without cancellation, cannot be commuted to begin with a letter in excluded_letters\n",
    "        '''\n",
    "        if excluded_letters == self.alphabet:\n",
    "            print(\"It appears that every letter has been excluded. Returning an automaton that accepts only the empty string\")\n",
    "            SingleState = FSMState('origin', is_initial = True, is_final = True)\n",
    "            return ConcatableAutomaton({SingleState:[]})\n",
    "        sorted_excluded_letters = sorted(excluded_letters, key = lambda x: self.o_map[x])\n",
    "        TransitionList = []\n",
    "        Frontier = []\n",
    "        StartStateName = tuple(sorted_excluded_letters)\n",
    "        # StartStateName = \",\".join(str(letter) for letter in sorted(excluded_letters, key = lambda x: self.o_map[x]))\n",
    "        StartState = FSMState(StartStateName, is_initial = True, is_final = True)\n",
    "        for nextletter in self.alphabet.difference(excluded_letters):\n",
    "            NextName = tuple(sorted(excluded_letters.intersection(self.c_map[nextletter]), key = lambda x: self.o_map[x]))\n",
    "            NextState = FSMState(NextName, is_initial = (NextName == StartStateName), is_final = True)\n",
    "            TransitionList.append(FSMTransition(StartState, NextState, nextletter))\n",
    "            Frontier.append(NextState)\n",
    "            \n",
    "        #FinishedStates keeps track of which vertices we have already found all the edges for.\n",
    "        \n",
    "        FinishedStates = [StartState]\n",
    "        while len(Frontier)>0:\n",
    "            SourceState = Frontier.pop(0)\n",
    "            if SourceState in FinishedStates:\n",
    "                continue\n",
    "        \n",
    "            SourceSet = set(SourceState.label())\n",
    "            FinishedStates.append(SourceState)\n",
    "            for nextletter in self.alphabet.difference(SourceSet):\n",
    "                NextName = tuple(sorted(SourceSet.intersection(self.c_map[nextletter]), key = lambda x: self.o_map[x]))\n",
    "                NextState = FSMState(NextName, is_initial = (NextName == StartStateName), is_final = True)\n",
    "                Frontier.append(NextState)\n",
    "                TransitionList.append(FSMTransition(SourceState, NextState, nextletter))\n",
    "       \n",
    "        #print('TransitionList is')\n",
    "        #print(TransitionList)\n",
    "        return(ConcatableAutomaton(TransitionList))\n",
    "        \n",
    "\n",
    "    def odd_accepter_machine(self) -> ConcatableAutomaton:\n",
    "        '''\n",
    "        This machine will accept words of odd length. Since words will be passed as lists of elements of the alphabet, the len function could do this.\n",
    "        However, the tools in sage.combinat.finite_state_machine don't easily facilitate combining FSMs with functions.\n",
    "\n",
    "        :return: An automaton whose accepted language consists of (unreduced) words of odd length.\n",
    "        '''\n",
    "\n",
    "        EvenState = FSMState('even', is_initial = True, is_final = False)\n",
    "        OddState = FSMState('odd', is_initial = False, is_final = True)\n",
    "        TransitionList = []\n",
    "        for letter in self.alphabet:\n",
    "            TransitionList.append(FSMTransition(EvenState, OddState, letter))\n",
    "            TransitionList.append(FSMTransition(OddState, EvenState, letter))\n",
    "        return ConcatableAutomaton(TransitionList)\n",
    "\n",
    "    def even_accepter_machine(self) -> ConcatableAutomaton:\n",
    "        '''\n",
    "        This machine will accept words of even length. Since words will be passed as lists of elements of the alphabet, the len function could do this.\n",
    "        However, the tools in sage.combinat.finite_state_machine don't easily facilitate combining FSMs with functions.\n",
    "\n",
    "        :return: An automaton whose accepted language consists of (unreduced) words of odd length.\n",
    "        '''\n",
    "\n",
    "        EvenState = FSMState('even', is_initial = True, is_final = True)\n",
    "        OddState = FSMState('odd', is_initial = False, is_final = False)\n",
    "        TransitionList = []\n",
    "        for letter in self.alphabet:\n",
    "            TransitionList.append(FSMTransition(EvenState, OddState, letter))\n",
    "            TransitionList.append(FSMTransition(OddState, EvenState, letter))\n",
    "        return ConcatableAutomaton(TransitionList)\n",
    "        \n",
    "    def __shortlex_machine(self, restricted_alphabet = None) -> ConcatableAutomaton:\n",
    "        \"\"\"\n",
    "        Generate an FSM that prevents letters from being written that either cancel or should have already been written. \n",
    "        The states of this automaton represent the list of letters that a word cannot be followed by if it is to remain shortlex\n",
    "\n",
    "        :param restricted_alphabet: if desired, pass a subset of self.alphabet to get the shortlex machine for the special subgroup defined by the vertices in restricted_alphabet. If this set is empty, an FSM recognizing the empty word is returned.\n",
    "        \n",
    "        :return: An automaton whose accepted language consists of shortlex words.\n",
    "        \"\"\"\n",
    "        if restricted_alphabet is None:\n",
    "            restricted_alphabet = self.alphabet\n",
    "        if not restricted_alphabet.issubset(self.alphabet):\n",
    "            raise ValueError(\"argument restricted_alphabet is not a subset of self.alphabet\")\n",
    "        if restricted_alphabet == set():\n",
    "            print(\"You have requested the shortlex machine on an empty alphabet. Returning an automaton that accepts only the empty string\")\n",
    "            SingleState = FSMState('origin', is_initial = True, is_final = True)\n",
    "            return ConcatableAutomaton({SingleState:[]})\n",
    "        \n",
    "        StartState = FSMState((), is_initial = True, is_final = True)\n",
    "        TransitionList = []\n",
    "        Frontier = []\n",
    "        States = [StartState]\n",
    "\n",
    "        # Initialize the frontier with the legal next letters for single letter words \n",
    "        for nextletter in restricted_alphabet:\n",
    "\n",
    "            # Set destination as the set of legal next letters for each letter\n",
    "            NextName = tuple(sorted((self.lesser_star[nextletter].intersection(restricted_alphabet)).union({nextletter}), key = lambda x: self.o_map[x]))\n",
    "            NextState = FSMState(NextName, is_initial = False, is_final = True)\n",
    "            TransitionList.append(FSMTransition(StartState, NextState, nextletter))\n",
    "            \n",
    "            Frontier.append(NextState)\n",
    "\n",
    "        # Run BFS until we have finished the machine\n",
    "        while len(Frontier) > 0:\n",
    "            SourceState = Frontier.pop(0)\n",
    "\n",
    "            # We have already considered source and all its outgoing edges, we can skip it\n",
    "            if SourceState in States:\n",
    "                continue\n",
    "            States.append(SourceState)\n",
    "\n",
    "            # Record outgoing edges (i.e. possible next letters) from SourceState. This is guaranteed to be unique by above if-statement\n",
    "            SourceSet = set(SourceState.label())\n",
    "            for nextletter in restricted_alphabet.difference(SourceSet):\n",
    "                # This line computes the new set of forbidden letters\n",
    "                NextSet = SourceSet.intersection(self.c_map[nextletter]).union(self.lesser_star[nextletter].intersection(restricted_alphabet)).union({nextletter})\n",
    "                NextName = tuple(sorted(NextSet, key = lambda x: self.o_map[x]))\n",
    "                #We can never return to the original state, so the next state is always final and never initial.\n",
    "                NextState = FSMState(NextName, is_initial = False, is_final = True)\n",
    "                                \n",
    "                # Add NextState to our frontier to ensure all vertices are reached\n",
    "                Frontier.append(NextState)\n",
    "                TransitionList.append(FSMTransition (SourceState, NextState, nextletter))\n",
    "               \n",
    "        #print(f\"ShortLex Machine on alphabet {restricted_alphabet} Completed: Graph with \\n\\t\\t{len(States)} Vertices and \\n\\t\\t{len(TransitionList)} Edges.\")\n",
    "        return (ConcatableAutomaton(TransitionList))\n",
    "    \n",
    "    def __geodesic_machine(self, restricted_alphabet = None)->ConcatableAutomaton:\n",
    "        \"\"\"\n",
    "        Generate an FSM that prevents letters from being written that cancel . \n",
    "        The states of this automaton represent the list of letters that a word cannot be followed by if it is to remain geodesic\n",
    "\n",
    "        :param restricted_alphabet: if desired, pass a subset of self.alphabet to get the geodesic machine for the special subgroup defined by the vertices in restricted_alphabet.\n",
    "        \n",
    "        :return: An automaton whose accepted language consists of geodesic words.\n",
    "        \"\"\"\n",
    "        if restricted_alphabet is None:\n",
    "            restricted_alphabet = self.alphabet\n",
    "        if not restricted_alphabet.issubset(self.alphabet):\n",
    "            raise ValueError(\"argument restricted_alphabet is not a subset of self.alphabet\")\n",
    "        if restricted_alphabet == set():\n",
    "            print(\"You have requested the geodesic machine on an empty alphabet. Returning an automaton that accepts only the empty string\")\n",
    "            SingleState = FSMState('origin', is_initial = True, is_final = True)\n",
    "            return ConcatableAutomaton({SingleState:[]})\n",
    "        \n",
    "        StartState = FSMState((), is_initial = True, is_final = True)\n",
    "        TransitionList = []\n",
    "        Frontier = []\n",
    "        States = [StartState]\n",
    "\n",
    "        # Initialize the frontier with the legal next letters for single letter words \n",
    "        for nextletter in restricted_alphabet:\n",
    "\n",
    "            # Set destination as the set of legal next letters for each letter\n",
    "            NextName = (nextletter)\n",
    "            NextState = FSMState(NextName, is_initial = False, is_final = True)\n",
    "            TransitionList.append(FSMTransition(StartState, NextState, nextletter))\n",
    "            \n",
    "            Frontier.append(NextState)\n",
    "\n",
    "        # Run BFS until we have finished the machine\n",
    "        while len(Frontier) > 0:\n",
    "            SourceState = Frontier.pop(0)\n",
    "\n",
    "            # We have already considered source and all its outgoing edges, we can skip it\n",
    "            if SourceState in States:\n",
    "                continue\n",
    "            States.append(SourceState)\n",
    "\n",
    "            # Record outgoing edges (i.e. possible next letters) from SourceState. This is guaranteed to be unique by above if-statement\n",
    "            SourceSet = set(SourceState.label())\n",
    "            for nextletter in restricted_alphabet.difference(SourceSet):\n",
    "                # This line computes the new set of forbidden letters\n",
    "                NextSet = SourceSet.intersection(self.c_map[nextletter]).union({nextletter})\n",
    "                NextName = tuple(sorted(NextSet, key = lambda x: self.o_map[x]))\n",
    "                #We can never return to the original state, so the next state is always final and never initial.\n",
    "                NextState = FSMState(NextName, is_initial = False, is_final = True)\n",
    "                                \n",
    "                # Add NextState to our frontier to ensure all vertices are reached\n",
    "                Frontier.append(NextState)\n",
    "                TransitionList.append(FSMTransition (SourceState, NextState, nextletter))\n",
    "               \n",
    "        #print(f\"Geodesic Machine on alphabet {restricted_alphabet} completed: Graph with \\n\\t\\t{len(States)} Vertices and \\n\\t\\t{len(TransitionList)} Edges.\")\n",
    "        return (ConcatableAutomaton(TransitionList))\n",
    "    \n",
    "    def shortlex_suffix_machine(self) -> ConcatableAutomaton:\n",
    "        return self.__shortlex_machine().concatable_intersection(self.__first_letter_excluder(set(self.ray)))\n",
    "\n",
    "    def geodesic_suffix_machine(self) -> ConcatableAutomaton:\n",
    "        return self.__geodesic_machine().concatable_intersection(self.__first_letter_excluder(set(self.ray)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68e7d44c-42fc-44f4-baaf-0d3335bdba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Divergence_FSM_Generator(Rips_FSM_Generator):\n",
    "    def __init__(self, commutation_dict:dict[str, set], order_dict: dict[str, int], ray: list[str]):\n",
    "        \n",
    "        '''\n",
    "        This object will make the necessary automata for computing the Divergence Graph. \n",
    "    \n",
    "        :param commutation_dict: A dictionary representation of a defining graph. A letter (key) is associated with a list of letters (value) that the key letter commutes with. This list should not include the key letter.\n",
    "        Note: this program does not check that commutation_dict is symmetrical. You need to make sure that if your input allows a_i to commute with a_j, then a_j is also allowed to commute with a_i.\n",
    "        :param order_dict: A dictionary representation of a total ordering on the letter in the defining graph. A letter (key) is associated with an index (value) that represents that letters relative position in the ordering.\n",
    "        :param ray: A list of two characters that will be used to generate the chosen ray to infinity. In the paper these are referred to as a_i and a_j respectively.\n",
    "        '''\n",
    "\n",
    "        if not len(ray) == 2:\n",
    "            raise ValueError (\"The defining ray should have two letters\")\n",
    "        elif ray [1] in commutation_dict[ray[0]]:\n",
    "            raise ValueError (\"The defining ray consists of two letters which commute\")\n",
    "        \n",
    "        self.c_map = commutation_dict\n",
    "        self.o_map = order_dict\n",
    "        self.alphabet = set().union(letter for letter in self.o_map)\n",
    "        self.ray = ray\n",
    "\n",
    "        self.WordGeneratorMachine = WordGenerator(self.c_map, self.o_map)\n",
    "        \n",
    "        StringOfAllLetters = ''.join(letter for letter in self.alphabet)\n",
    "        if '-' in StringOfAllLetters:\n",
    "            raise ValueError ('''The character '-' is reserved to be the blank character''')\n",
    "        if ',' in StringOfAllLetters:\n",
    "            raise ValueError('''The character ',' is reserved for delimiting lists''')\n",
    "        if '_' in StringOfAllLetters:\n",
    "            raise ValueError(''' The character '_' is reserved for the word breaks in horocyclic suffices''')\n",
    "        \n",
    "        #the lesser_star dictionary agrees with the function Star_< in the paper. When passed a key of a letter, it returns the set of letters that commute with and precede the key. Note the strict inequality.\n",
    "        self.lesser_star = {}\n",
    "        for letter in self.alphabet:\n",
    "            LesserStarOfLetter = set(filter(lambda x: self.o_map[x] < self.o_map[letter], self.c_map[letter]))\n",
    "            self.lesser_star[letter] = LesserStarOfLetter\n",
    "        self.greater_star = {}\n",
    "        for letter in self.alphabet:\n",
    "            self.greater_star[letter] = self.c_map[letter].difference(self.lesser_star[letter])\n",
    "\n",
    "    def horocyclic_suffix_machine_1(self) -> ConcatableAutomaton:\n",
    "        #The w_1 machine accepts words spelled in the letters that commute with both letters of the ray and precede the second one (a_j in the paper)\n",
    "        w1_machine = self._Rips_FSM_Generator__shortlex_machine(self.c_map[self.ray[0]].intersection(self.lesser_star[self.ray[1]]))\n",
    "\n",
    "        return (w1_machine)\n",
    "\n",
    "    def horocyclic_suffix_machine_2(self) -> ConcatableAutomaton:\n",
    "        #The w_2 machine accepts words spelled in the letters that commute with both letters of the ray, precede the first one (a_i in the paper), and follow the second one.\n",
    "        w2_machine = self._Rips_FSM_Generator__shortlex_machine(self.lesser_star[self.ray[0]].intersection(self.greater_star[self.ray[1]]))\n",
    "\n",
    "        return(w2_machine)\n",
    "\n",
    "    \n",
    "    def horocyclic_suffix_machine_1234(self) -> ConcatableAutomaton:\n",
    "        '''\n",
    "        Generate an FSM which accepts one of the two horocyclically shortlex word forms.\n",
    "\n",
    "        :return: an Automaton whose accepted language is the set of words w_1w_2w_3w_4 as described in the paper.\n",
    "        ''' \n",
    "\n",
    "        #w_3w_4 is a concattenation of shortlex words such that\n",
    "        # 1. w_3 is spelled with letters commuting with and preceding a_j, and which do not commute with a_i\n",
    "        # 2. w_4 cannot be made to begin with a_i, a_j, or a letter commuting with and preceding a_j\n",
    "        # 3. w_3w_4, as a whole, cannot be rearranged to begin with a letter commuting with both letters and preceding a_i\n",
    "\n",
    "        w3_machine = self._Rips_FSM_Generator__shortlex_machine(self.lesser_star[self.ray[1]]).concatable_intersection(self._Rips_FSM_Generator__first_letter_excluder(self.c_map[self.ray[0]]))\n",
    "\n",
    "        #This machine is so-named because its language is not exactly the words w_4, since in fact whether a word is allowed to be w_4 depends on w_3 by condition 3 above\n",
    "        w4_machine_approx = self._Rips_FSM_Generator__shortlex_machine().concatable_intersection(self._Rips_FSM_Generator__first_letter_excluder(self.lesser_star[self.ray[1]].union(set(self.ray))))\n",
    "        #If there are bugs, it's because of this machine, but I believe this machine is correct.\n",
    "\n",
    "        w1_machine = self.horocyclic_suffix_machine_1()\n",
    "        w2_machine = self.horocyclic_suffix_machine_2()\n",
    "        w12_machine = w1_machine.unambiguous_concatenation(w2_machine)\n",
    "        \n",
    "        w3w4_machine = (w3_machine.unambiguous_concatenation(w4_machine_approx)).concatable_intersection(self._Rips_FSM_Generator__first_letter_excluder({self.ray[0]}.union(self.lesser_star[self.ray[0]].intersection(self.c_map[self.ray[1]]))))\n",
    "\n",
    "        return w12_machine.unambiguous_concatenation(w3w4_machine)\n",
    "\n",
    "    def horocyclic_suffix_machine_1256(self) -> ConcatableAutomaton:\n",
    "  \n",
    "        '''\n",
    "        Generate an FSM which accepts one of the two horocyclically shortlex word forms.\n",
    "\n",
    "        :return: an Automaton whose accepted language is the set of words w_1w_2w_5w_6 as described in the paper.\n",
    "        ''' \n",
    "\n",
    "        #w_5w_6 is a concattenation of shortlex words such that\n",
    "        # 1. w_5 is spelled with letters commuting with and preceding a_i, and which do not commute with a_j\n",
    "        # 2. w_6 cannot be made to begin with a_i, a_j, or a letter commuting with and preceding a_i\n",
    "        # 3. w_5w_6, as a whole, cannot be rearranged to begin with a letter commuting with both a_i and a_j and preceding a_j\n",
    "        \n",
    "        w5_machine = self._Rips_FSM_Generator__shortlex_machine(self.lesser_star[self.ray[0]]).concatable_intersection(self._Rips_FSM_Generator__first_letter_excluder(self.c_map[self.ray[1]]))\n",
    "\n",
    "        #This machine is so-named because its language is not exactly the words w_6, since in fact whether a word is allowed to be w_6 depends on w_5 by condition 3 above\n",
    "        w6_machine_approx = self._Rips_FSM_Generator__shortlex_machine().concatable_intersection(self._Rips_FSM_Generator__first_letter_excluder(self.lesser_star[self.ray[0]].union(set(self.ray))))\n",
    "        #If there are bugs, it's because of this machine, but I believe this machine is correct.\n",
    "\n",
    "        w1_machine = self.horocyclic_suffix_machine_1()\n",
    "        w2_machine = self.horocyclic_suffix_machine_2()\n",
    "        w12_machine = w1_machine.unambiguous_concatenation(w2_machine)\n",
    "        \n",
    "        w5w6_machine = (w5_machine.unambiguous_concatenation(w6_machine_approx)).concatable_intersection(self._Rips_FSM_Generator__first_letter_excluder({self.ray[1]}.union(self.lesser_star[self.ray[1]].intersection(self.c_map[self.ray[0]]))))\n",
    "\n",
    "        return w12_machine.unambiguous_concatenation(w5w6_machine)\n",
    "\n",
    "    #We will not use the even_horocyclic_suffix_machine or the odd_horocyclic_suffix_machine in practice.\n",
    "    \n",
    "    def even_horocyclic_suffix_machine(self) -> ConcatableAutomaton:\n",
    "\n",
    "        return ((self.horocyclic_suffix_machine_1256())._interspersal(self.horocyclic_suffix_machine_1234()))\n",
    "\n",
    "    def odd_horocyclic_suffix_machine(self) -> ConcatableAutomaton:\n",
    "\n",
    "        return ((self.horocyclic_suffix_machine_1234())._interspersal(self.horocyclic_suffix_machine_1256()))\n",
    "\n",
    "    def horocyclic_edge_checker(self, SubwordDict) -> Automaton:\n",
    "        '''\n",
    "        This machine will check whether there is a divergence graph edge between two horocyclic suffixes of the same length.\n",
    "        The inputs will be pairs (WLetter,VLetter) or the pair ('-','-'). The latter denotes the end of the word.\n",
    "\n",
    "        The subroutines generate_states_without_uncancelables, generate_first_noncanceling_transitions, get_nonterminal_transitions,\n",
    "        and get_double_blank_transition will all be defined later.\n",
    "        \n",
    "        :param SubwordDict: A dictionary that keeps track of which letters first appear in which subword. It will have values 1-4 if the two words are of the same length and values 1-3 if the two are of different lengths.\n",
    "        This is because in the case that w_suff is 1 letter shorter than v_suff, we will compare w_1w_2w_3self.ray[1]w_4- with v_1v_2 v_6-, or w_1w_2w_5 self.ray[0]w_6- with v_1v_2 v_4-.\n",
    "        In the first case, letters of w_3self.ray[1]w_4 can cancel with those of v_6, while in the second case, letters of w_5self.ray[0]w_6 can cancel with those of v_4.\n",
    "        \n",
    "        :return: an Automaton which accepts as inputs pairs of letters, one from w and one from v, such that the words such that the lengths of each word are equal and there is no uncancelable pair\n",
    "        '''\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        NonFinalStates = []\n",
    "        FinalStates = []\n",
    "        TotalTransitions = []\n",
    "        FinishedStates = []\n",
    "\n",
    "        FinalSubword = max(SubwordDict.values())\n",
    "\n",
    "        (StatesWithoutUncancelables, NewTransitions) = self.generate_states_without_uncancelables(SubwordDict)\n",
    "\n",
    "        print('Completed the uncancelable states. There are ', len(StatesWithoutUncancelables), ' of them.')\n",
    "        \n",
    "        NonFinalStates.extend(StatesWithoutUncancelables)\n",
    "        TotalTransitions.extend(NewTransitions)\n",
    "        \n",
    "        for StateWithoutUncancelables in StatesWithoutUncancelables:\n",
    "            (NewStates, NewTransitions) = self.generate_first_noncanceling_transitions(StateWithoutUncancelables,SubwordDict)\n",
    "            NonFinalStates.extend(NewStates)\n",
    "            TotalTransitions.extend(NewTransitions)\n",
    "            FinishedStates.append(StateWithoutUncancelables)\n",
    "\n",
    "        print('Completed the first batch of transitions. There are ', len(TotalTransitions), 'transitions and ', len(set(NonFinalStates)), ' states in total')\n",
    "        \n",
    "        while len(NonFinalStates)>0:\n",
    "            SourceState = NonFinalStates.pop(0)\n",
    "            if SourceState in FinishedStates:\n",
    "                continue\n",
    "\n",
    "            (NewStates, NewTransitions) = self.get_nonterminal_transitions(SourceState, SubwordDict)\n",
    "            NonFinalStates.extend(NewStates)\n",
    "            TotalTransitions.extend(NewTransitions)\n",
    "            FinishedStates.append(SourceState)\n",
    "\n",
    "        print('Completed the nonterminal transitions. There are ', len(TotalTransitions), ' transitions and ', len(set(FinishedStates)), ' states in total')\n",
    "        \n",
    "        for SourceState in FinishedStates:\n",
    "            try:\n",
    "                (FinalState, FinalTransition) = self.get_double_blank_transition(SourceState, FinalSubword)\n",
    "            except TypeError:\n",
    "                continue\n",
    "            FinalStates.append(FinalState)\n",
    "            TotalTransitions.append(FinalTransition)\n",
    "\n",
    "        print('completed the final transitions. There are ', len(TotalTransitions), 'transitions and ', len(set(FinalStates)), ' final states in total')\n",
    "        \n",
    "        return Automaton(TotalTransitions)\n",
    "\n",
    "    def horocyclic_edge_checker_different_length(self) -> Automaton:\n",
    "        '''\n",
    "        This machine will check whether there is an uncancelable pair between two horocyclic suffixes of length differing by 1. The first input is w and the second is v.\n",
    "        v_3 or v_5, depending on the form of v, is necessarily empty to have such an edge. However, this machine will not check this fact explicitly.\n",
    "        The inputs will be pairs (WLetter, VLetter) or the pair ('-', '-'). The latter denotes the end of the word.\n",
    "        \n",
    "        The subroutines generate_states_without_uncancelables, generate_first_noncanceling_transitions, get_nonterminal_transitions,\n",
    "        and get_single_blank_transition will all be defined later.\n",
    "        \n",
    "        :return: an Automaton which accepts pairs (w_1w_2w_3self.ray[1]w_4-, v_1v_2 v_6-) and (w_1w_2w_4 self.ray[0]w_6-, v_1v_2 v_4-) such that the lengths of each word are equal and there is no uncancelable pair\n",
    "        '''\n",
    "\n",
    "        #if not (mode == '1234' or mode == '1256'):\n",
    "            #raise ValueError(''' The mode should be either '1234' or '1256' ''')\n",
    "\n",
    "        #This dictionary keeps track of the necessary changes to the parameters n_v and n_w\n",
    "        SubwordDict = {}\n",
    "        #The letters that commute with and precede both ray letters appear first in w_1\n",
    "        for letter in self.c_map[self.ray[0]].intersection(self.lesser_star[self.ray[1]]):\n",
    "            SubwordDict[letter] = 1\n",
    "        #The letters that commute with both ray letters and precede only the first appear first in w_2\n",
    "        for letter in self.lesser_star[self.ray[0]].intersection(self.greater_star[self.ray[1]]):\n",
    "            SubwordDict[letter] = 2\n",
    "        #Every other letter appears in one of the last two subwords, and these are all lumped into a single case.\n",
    "        for letter in self.alphabet:\n",
    "            try:\n",
    "                SubwordDict[letter]\n",
    "            except KeyError:\n",
    "                SubwordDict[letter] = 3\n",
    "\n",
    "        NonFinalStates = []\n",
    "        PreFinalStates = []\n",
    "        FinalStates = []\n",
    "        TotalTransitions = []\n",
    "        FinishedStates = []\n",
    "\n",
    "        #The beginning of this machine is the same as the previous one. All that needs to change is that we need to check that there are precisely two input pairs ('-', 'letter').\n",
    "        #Because of these two blank characters at the end of the word w, there is no need for an input ('-', '-') to indicate that the word has ended.\n",
    "        \n",
    "        (StatesWithoutUncancelables, NewTransitions) = self.generate_states_without_uncancelables(SubwordDict)\n",
    "\n",
    "        print('Completed the uncancelable states. There are ', len(StatesWithoutUncancelables), ' of them.')\n",
    "        \n",
    "        NonFinalStates.extend(StatesWithoutUncancelables)\n",
    "        TotalTransitions.extend(NewTransitions)\n",
    "        \n",
    "        for StateWithoutUncancelables in StatesWithoutUncancelables:\n",
    "            (NewStates, NewTransitions) = self.generate_first_noncanceling_transitions(StateWithoutUncancelables,SubwordDict)\n",
    "            NonFinalStates.extend(NewStates)\n",
    "            TotalTransitions.extend(NewTransitions)\n",
    "            FinishedStates.append(StateWithoutUncancelables)\n",
    "\n",
    "        print('Completed the first batch of transitions. There are ', len(TotalTransitions), 'transitions and ', len(NonFinalStates), ' states in total')\n",
    "        \n",
    "        while len(NonFinalStates) > 0:\n",
    "            SourceState = NonFinalStates.pop(0)\n",
    "            if SourceState in FinishedStates:\n",
    "                continue\n",
    "\n",
    "            (NewStates, NewTransitions) = self.get_nonterminal_transitions(SourceState, SubwordDict)\n",
    "            NonFinalStates.extend(NewStates)\n",
    "            TotalTransitions.extend(NewTransitions)\n",
    "            FinishedStates.append(SourceState)\n",
    "\n",
    "        print('Completed the nonterminal transitions. There are ', len(TotalTransitions), ' transitions and ', len(set(FinishedStates)), ' states in total')\n",
    "        \n",
    "        for SourceState in set(FinishedStates):\n",
    "            for letter in SourceState.label()[9]:\n",
    "                holder = self.get_single_blank_transition(SourceState, letter, SubwordDict)\n",
    "                if holder is None:\n",
    "                    continue\n",
    "                (PreFinalState, PreFinalTransition) = holder\n",
    "                PreFinalStates.append(PreFinalState)\n",
    "                TotalTransitions.append(PreFinalTransition)\n",
    "\n",
    "        print('Completed the first set of blank transitions. There are ', len(TotalTransitions), 'transitions and ', len(set(PreFinalStates)), ' pre-final states in total')\n",
    "\n",
    "        for SourceState in set(PreFinalStates):\n",
    "            for letter in SourceState.label()[9]:\n",
    "                holder = self.get_single_blank_transition(SourceState, letter, SubwordDict)\n",
    "                if holder is None:\n",
    "                    continue\n",
    "                (FinalState, FinalTransition) = holder\n",
    "                FinalStates.append(FinalState)\n",
    "                TotalTransitions.append(FinalTransition)\n",
    "\n",
    "        print('Completed the second set of blank transitions. There are ', len(TotalTransitions), 'transitions and ', len(set(FinalStates)), ' final states in total')\n",
    "        \n",
    "        return Automaton(TotalTransitions)\n",
    "        \n",
    "    '''\n",
    "    What follow are subroutines for the methods horocyclic_edge_checker_same_length and horocyclic_edge_checker_different_length.\n",
    "    To improve performance and make certain features of sage.combinat.finite_state_machine usable, the state labels must be hashable, but to make changes, we will want mutable types.\n",
    "\n",
    "    The following describes the state labels\n",
    "    4 entries for the subwords u_j (j=1, 2, 3, 4) of potentially cancelable letters. These will be tuples (hashable) or instances of the Word Class (mutable)\n",
    "    4 entries for the geodesic first letters of each of the u_j, and of each of their truncations. These will be tuples of pairs of tuples (hashable) or lists of pairs of sets (mutable)\n",
    "    This will be formatted as a tuple or list of pairs (first letters, potential first letters).\n",
    "    These first 8 entries will alternate, so that the data for the subword u_j appears at indices 2*j-2 and 2*j-1.\n",
    "    1 entry for the uncancelable letters, in a tuple (hashable) or set (mutable).\n",
    "    1 entry for the letters that commute with each uncancelable letter, in a tuple (hashable) or set (mutable)\n",
    "    1 tuple of 2 integers n_w and n_v keeping track of which subword the two inputs are on.\n",
    "    1 bit. True will mean that the second input (v) is the one which contains the potentially cancelable letters. False will mean that the first input (w) contains the potentially cancelable letters. Its initial value is arbitrarily set to True.\n",
    "    The two inputs are the 'adding input' (the word that has the cancelable letters) and the 'canceling input'. So the bit True means that v is adding and w is canceling\n",
    "\n",
    "    All of the above data will be placed into a tuple (hashable) or list (mutable)\n",
    "    '''\n",
    "    \n",
    "    def generate_states_without_uncancelables(self, SubwordDict:dict[str: int]) -> tuple:\n",
    "        #There are at most 4 states without uncancelable letters. This method generates them and the transitions between them.\n",
    "        #:param SubwordDict: A dictionary whose keys are letters and whose values are the first subword that letter appears in.\n",
    "        #:return: A pair consisting of a list of states without uncancelable letters, and a list of the transitions between them.\n",
    "        \n",
    "        TransitionList = []\n",
    "        StatesWithoutUncancelables = []\n",
    "\n",
    "        #This state will always exist\n",
    "        InitialState = FSMState( ( (), (), (),  (), (), (), (), (), (), tuple(self.alphabet), (1, 1), True ),\n",
    "                              is_initial = True, is_final = False)\n",
    "\n",
    "        StatesWithoutUncancelables.append(InitialState)\n",
    "\n",
    "        #We only need a state without uncancelables for each subword that will actually appear.\n",
    "        for value in set(SubwordDict.values()).difference({1}):\n",
    "            NewState = FSMState( ( (), (), (),  (), (), (), (), (), (), tuple(self.alphabet), (value, value), True ) )\n",
    "            StatesWithoutUncancelables.append(NewState)\n",
    "               \n",
    "        for SourceState in StatesWithoutUncancelables:\n",
    "            for letter in self.alphabet:\n",
    "                NewSubword = max(SourceState.label()[10][0], SubwordDict[letter])\n",
    "                NewState = FSMState( ( (), (), (),  (), (), (), (), (), (), tuple(self.alphabet), (NewSubword, NewSubword), True ) ,\n",
    "                              is_initial = (NewSubword == 1), is_final = False)\n",
    "                TransitionList.append(FSMTransition(SourceState, NewState, (letter, letter)))\n",
    "\n",
    "        return (StatesWithoutUncancelables, TransitionList)\n",
    "\n",
    "    def generate_first_noncanceling_transitions(self, StateWithoutUncancelables:FSMState, SubwordDict:dict[str: int]) -> tuple:\n",
    "        #This method generates all the remaining transitions out of the 4 states without uncancelables\n",
    "        #:param StateWithoutUncancelables: An FSMState that is in the output state list of FSM_Generator.generate_states_without_uncancelables.\n",
    "        #:param SubwordDict: A dictionary whose keys are letters and whose values are the first subword that letter appears in.\n",
    "        #:return: A pair consisting of a list of the states that follow StateWithoutUncancelables and a list a of the transitions out of StateWithoutUncancelables.\n",
    "\n",
    "        if StateWithoutUncancelables.label()[8] != ():\n",
    "            raise ValueError('This state has uncancelable letters')\n",
    "        \n",
    "        ResultingStates = []\n",
    "        Transitions = []\n",
    "        \n",
    "        for LetterPair in product(self.alphabet, self.alphabet):\n",
    "            WLetter = LetterPair [0]\n",
    "            VLetter = LetterPair [1]\n",
    "            #We can assume the two commute, or else we immediately reach a failure state\n",
    "            if WLetter not in self.c_map[VLetter]:\n",
    "                #This includes the case that WLetter == VLetter\n",
    "                continue\n",
    "\n",
    "            #In this setting, we will need to change the value at every \n",
    "            NewLabel = self._mutable_label(StateWithoutUncancelables.label())\n",
    "            NewNW = max(NewLabel[10][0], SubwordDict[WLetter])                    \n",
    "            NewNV = max(NewLabel[10][1], SubwordDict[VLetter])\n",
    "            NewLabel[10] = (NewNW, NewNV)\n",
    "            #We compute the next value of the bit. True means that the v is the adding word and False means that w is the adding word.\n",
    "            NewBit = ((NewNW < NewNV) or (NewNW == NewNV and self.o_map[WLetter] < self.o_map[VLetter]))\n",
    "            NewLabel[11] = NewBit\n",
    "            AddingLetter = LetterPair[int(NewBit)]\n",
    "            AddingSubword = NewLabel[10][int(NewBit)]\n",
    "            CancelingLetter = LetterPair[1-int(NewBit)]\n",
    "            \n",
    "            #Add the AddingLetter\n",
    "            NewLabel[2*AddingSubword -2].append(AddingLetter)\n",
    "            #The AddingLetter is the first letter of the relevant word. The other possible first letters are those that commute with it.\n",
    "            NewLabel[2*AddingSubword -1].append( ({AddingLetter}, self.c_map[AddingLetter]) )\n",
    "            \n",
    "            #Since the Adding and Canceling letters do not equate, there is no need to check for cancelation. The CancelingLetter automatically becomes uncancelable.\n",
    "            NewLabel[8] = {CancelingLetter}\n",
    "            NewLabel[9].intersection_update(self.c_map[CancelingLetter])\n",
    "            \n",
    "            NewState = FSMState(self._hashable_label(NewLabel))\n",
    "            ResultingStates.append(NewState)\n",
    "            NewTransition = FSMTransition(StateWithoutUncancelables, NewState, LetterPair)\n",
    "            Transitions.append(NewTransition)\n",
    "        return(ResultingStates, Transitions)\n",
    "\n",
    "    def get_nonterminal_transitions(self, SourceState:FSMState, SubwordDict: dict[str: int]) -> tuple:\n",
    "        #This method generates all the nonterminal successors of a state that has some uncancelable letters\n",
    "        #:param SourceState: An FSMState with some uncancelable letters. \n",
    "        #:param SubwordDict: A dictionary whose keys are letters and whose values are the first subword that letter appears in.\n",
    "        #:return: A pair consisting of a list of the states that follow SourceState and a list a of the transitions out of SourceState.\n",
    "\n",
    "        OldBit = SourceState.label()[11]\n",
    "        (OldNW, OldNV) = SourceState.label()[10]\n",
    "        OldSubwordPair = (OldNW, OldNV)\n",
    "\n",
    "        ResultingStates = []\n",
    "        Transitions = []\n",
    "\n",
    "        for LetterPair in product(SourceState.label()[9], SourceState.label()[9]):\n",
    "            WLetter = LetterPair [0]\n",
    "            VLetter = LetterPair [1]\n",
    "            AddingLetter = LetterPair[int(OldBit)]\n",
    "            CancelingLetter = LetterPair[1-int(OldBit)]\n",
    "            \n",
    "            NewLabel = self._mutable_label(SourceState.label())\n",
    "            NewNW = max(NewLabel[10][0], SubwordDict[WLetter])                    \n",
    "            NewNV = max(NewLabel[10][1], SubwordDict[VLetter])\n",
    "            NewSubwordPair = (NewNW, NewNV)\n",
    "            AddingSubword = NewSubwordPair[int(OldBit)]\n",
    "            CancelingSubword = NewSubwordPair[1-int(OldBit)]\n",
    "            NewLabel[10] = NewSubwordPair\n",
    "\n",
    "            #Append the new letter to the relevant subword\n",
    "            NewLabel[2*AddingSubword-2].append(AddingLetter)\n",
    "            #Update the first leters\n",
    "            for FirstLettersSet in NewLabel[2*AddingSubword-1]:\n",
    "                if AddingLetter in FirstLettersSet[1]:\n",
    "                    FirstLettersSet[0].add(AddingLetter)\n",
    "                FirstLettersSet[1].intersection_update(self.c_map[AddingLetter])\n",
    "            NewLabel[2*AddingSubword-1].append( ({AddingLetter},self.c_map[AddingLetter]) )\n",
    "\n",
    "            #Compute the next bit value\n",
    "            PresentLetterList = NewLabel[0].word_as_list + NewLabel[2].word_as_list + NewLabel[4].word_as_list + NewLabel[6].word_as_list\n",
    "            PresentLetterSet = set(PresentLetterList)\n",
    "            #Check whether the bit value needs to be flipped\n",
    "            LettersFollowingAllPresentLetters = copy.copy(self.alphabet)\n",
    "            for letter in PresentLetterSet:\n",
    "                LettersFollowingAllPresentLetters.intersection_update(self.greater_star[letter])\n",
    "            BitFlip = ( (CancelingSubword > AddingSubword) or \\\n",
    "                       (CancelingSubword == AddingSubword) and CancelingLetter in LettersFollowingAllPresentLetters \\\n",
    "                      )\n",
    "            #exor True is the same as not, while exor False does nothing.\n",
    "            NewLabel[11] = OldBit ^ BitFlip\n",
    "\n",
    "            if BitFlip:\n",
    "                #Every previously cancelable letter will become uncancelable. \n",
    "                #This will create an uncancelable pair if any of them fail to cancel with one another or with the CancelingLetter.\n",
    "                #We also check whether there are any duplicates among the PresentLetters.\n",
    "                #It is not possible for the CancelingLetter to be in PresentLetters in this case, so we need not check for disjointness.\n",
    "                if (len(PresentLetterList) > len(PresentLetterSet)) or (not (self._test_set_commutation(PresentLetterSet) and self._test_set_pair_commutation({CancelingLetter},PresentLetterSet))):\n",
    "                    continue\n",
    "                                \n",
    "                #Add every remaining cancelable letter into the uncancelable set\n",
    "                NewLabel[8] = NewLabel[8].union(PresentLetterSet)\n",
    "                for letter in PresentLetterSet:\n",
    "                    NewLabel[9].intersection_update(self.c_map[letter])\n",
    "            \n",
    "                #Delete every previously cancelable letter, and initialize a new single cancelable letter.\n",
    "                #Because we have just flipped the bit, the NewCancelingSubword and CancelingLetter take the place that the NewAddingSubword and AddingLetter had\n",
    "                \n",
    "                for i in range(0,4):\n",
    "                    NewLabel[2*i] = self.WordGeneratorMachine.word([])\n",
    "                    NewLabel[2*i+1] = []\n",
    "                NewLabel[2*CancelingSubword-2] = self.WordGeneratorMachine.word(CancelingLetter)\n",
    "                NewLabel[2*CancelingSubword-1].append( ({CancelingLetter}, self.c_map[CancelingLetter]) )\n",
    "                NewState = FSMState(self._hashable_label(NewLabel))\n",
    "                ResultingStates.append(NewState)\n",
    "                NewTransition = FSMTransition(SourceState, NewState, LetterPair)\n",
    "                Transitions.append(NewTransition)\n",
    "                continue\n",
    "\n",
    "            #Since the bit has not flipped, we just need to process the canceling letter.\n",
    "            NewLabel = self.process_canceling_letter(NewLabel, CancelingLetter, SubwordDict)\n",
    "            if NewLabel is None:\n",
    "                continue\n",
    "            NewState = FSMState(self._hashable_label(NewLabel))\n",
    "            ResultingStates.append(NewState)\n",
    "            NewTransition = FSMTransition(SourceState, NewState, (WLetter, VLetter))\n",
    "            Transitions.append(NewTransition)\n",
    "\n",
    "        return (ResultingStates, Transitions)\n",
    "\n",
    "    def process_canceling_letter(self, Label:list, CancelingLetter:str, SubwordDict:dict[str: int])-> list:\n",
    "        #This method takes a mutable label of an FSMState to which the AddingLetter has already been added and for which the bit has not flipped, and evaluates whether the CancelingLetter cancels\n",
    "        #This method updates the label to change the cancelable letters, uncancelable set, and list of accepted next letters appropriately.\n",
    "        #:param Label: the mutable label of an FSMState.\n",
    "        #:param CancelingLetter: the letter whose cancelation is to be tested.\n",
    "        #:param SubwordDict: A dictionary whose keys are letters and whose values are the first subword that letter appears in.\n",
    "        #:return: The mutable label of the resulting state, or None if processing CancelingLetter creates an uncancelable pair.\n",
    "\n",
    "        CancelingSubword = Label[10][1-int(Label[11])]\n",
    "        NewUncancelableList = []\n",
    "        #If a new subword has started, then the remaining letters from the previous subword(s) become uncancellable\n",
    "        for i in range (0, CancelingSubword-1):\n",
    "            NewUncancelableList.extend(Label[2*i].word_as_list)\n",
    "            Label[2*i] = self.WordGeneratorMachine.word([])\n",
    "            Label[2*i+1] = []\n",
    "        NewUncancelables = set(NewUncancelableList)\n",
    "        #This will create an uncancellable pair if any of the newly uncancelable letters fail to commute with one another, or any of them fail to commute with a remaining letter, or if they don't commute with the CancelingLetter\n",
    "        #Since there may be more NewUncancelables after checking whether the CancelingLetter cancels all we must check now is whether the CancelingLetter commutes to the matching AddingSubword \n",
    "        #It is not possible for CancelingLetter to be in NewUncancelables because because then CancelingLetter would have to have appeared in the adding subword earlier than possible. So there is not need to ask for disjointness\n",
    "        if not self._test_set_pair_commutation({CancelingLetter}, NewUncancelables):\n",
    "            return (None)\n",
    "\n",
    "        #Now we check whether the CancelingLetter actually cancels.\n",
    "        #This idiom avoids problems with indexing into empty lists.\n",
    "        if CancelingLetter in next(iter(Label[2*CancelingSubword-1]), (set(), set()))[0]:\n",
    "            CancelingIndex = Label[2*CancelingSubword-2].index(CancelingLetter)\n",
    "            #These letters have just become uncancellable.\n",
    "            NewUncancelableList.extend(Label[2*CancelingSubword-2][:CancelingIndex])\n",
    "            #This is the remaining potentially cancelable word.\n",
    "            Label[2*CancelingSubword-2] = self.WordGeneratorMachine.word(Label[2*CancelingSubword-2][CancelingIndex+1:])\n",
    "            Label[2*CancelingSubword-1] = Label[2*CancelingSubword-1][CancelingIndex+1:]\n",
    "            #Update which letters are present\n",
    "            RemainingLetters = set(Label[0].word_as_list).union(set(Label[2].word_as_list),set(Label[4].word_as_list),set(Label[6].word_as_list))\n",
    "            #Check whether there are duplicate uncancellable letters\n",
    "            NewUncancelables = set(NewUncancelableList)\n",
    "            if len(NewUncancelableList) > len(NewUncancelables):\n",
    "                return(None)\n",
    "            #Check whether there is an uncancellable pair, either between the new uncancelables or with the remaining letters. In this case we will demand disjointness.\n",
    "            if not (self._test_set_pair_commutation(NewUncancelables , RemainingLetters, AllDistinct = True) and self._test_set_commutation(NewUncancelables)):\n",
    "                return(None)\n",
    "            #If there are no uncancelable pairs, then we get a new transition. We will update the uncancelable set and the set of accepted next letters outside the if statement.\n",
    "            for letter in NewUncancelables:\n",
    "                Label[8].add(letter)\n",
    "                Label[9].intersection_update(self.c_map[letter])\n",
    "            return(Label)\n",
    "        else:\n",
    "            #If the CancelingLetter does not cancel, then it joins the uncancelable set. We check whether this creates an uncancelable pair.\n",
    "            NewUncancelables.add(CancelingLetter)\n",
    "            RemainingLetters = set(Label[0].word_as_list).union(set(Label[2].word_as_list),set(Label[4].word_as_list),set(Label[6].word_as_list))\n",
    "            if not (self._test_set_pair_commutation(NewUncancelables, RemainingLetters, True) and self._test_set_commutation(NewUncancelables)):\n",
    "                return(None)\n",
    "            #If there are no uncancelable pairs, then we get a new transition.\n",
    "            for letter in NewUncancelables:\n",
    "                Label[8].add(letter)\n",
    "                Label[9].intersection_update(self.c_map[letter])\n",
    "            return(Label)\n",
    "    \n",
    "    def get_double_blank_transition(self, SourceState:FSMState, FinalSubword:int)->tuple:\n",
    "        #This method takes any nonterminal SourceState and computes the outgoing transition labeled ('-', '-').\n",
    "        #:param SourceState: a non-final FSMState.\n",
    "        #:param FinalSubword: 3 or 4, depending on the number of different values of SubwordDict.\n",
    "        #:return: A pair consisting of a final state and a transition from SourceState to this final state labeled is ('-', '-'), or None if ending the inputs here yields an uncancelable pair.\n",
    "\n",
    "        if SourceState.is_final:\n",
    "            raise ValueError('The provided state is final already')\n",
    "        NewLabel = self._mutable_label(SourceState.label())\n",
    "        NewUncancelableList = []\n",
    "        for i in range (1, FinalSubword):\n",
    "            NewUncancelableList.extend(NewLabel[2*i-2].word_as_list)\n",
    "            NewLabel[2*i-2] = self.WordGeneratorMachine.word([])\n",
    "            NewLabel[2*i-1] = []\n",
    "        PresentLetters = set(NewLabel[2*FinalSubword - 2].word_as_list)\n",
    "        NewUncancelables = set(NewUncancelableList)\n",
    "        #Checking whether there are duplicate uncancelable letters.\n",
    "        if len(NewUncancelableList) > len(NewUncancelables):\n",
    "            return(None)\n",
    "        if not (self._test_set_commutation(NewUncancelables) and self._test_set_pair_commutation(NewUncancelables, PresentLetters, True)):\n",
    "            return(None)\n",
    "        for letter in NewUncancelables:\n",
    "            NewLabel[8].add(letter)\n",
    "            NewLabel[9].intersection_update(self.c_map[letter])\n",
    "        NewLabel[10] = (FinalSubword, FinalSubword)\n",
    "        \n",
    "        NewLabel.append('final')\n",
    "        #Necessary to prevent issues with states that have matching labels.\n",
    "        \n",
    "        NewState = FSMState(self._hashable_label(NewLabel), is_initial = False, is_final = True)\n",
    "        return( NewState, FSMTransition (SourceState, NewState, ('-','-')) )\n",
    "\n",
    "    '''\n",
    "    For the case where the words are different length, we will need one more subroutine. Since the words are of different lengths, we will assume the first input w is the shorter word.\n",
    "    Then we will pad the input so that w ends with 2 blank characters '-' so that w-- and v_1v_2v_3 self.ray[1] v_4 (or v_1v_2v_5 self.ray[0] v_6) are the same length\n",
    "    Therefore, we give a subroutine to process input pairs ('-', letter).\n",
    "    '''\n",
    "\n",
    "    def get_single_blank_transition(self, SourceState: FSMState, InputLetter: str, SubwordDict: dict[str:int]) -> tuple:\n",
    "        '''\n",
    "        This method takes a SourceState and returns the result of a transition labeled ('-', 'InputLetter').\n",
    "    \n",
    "        :param SourceState: an instance of FSMState of the above form.\n",
    "        :param InputLetter: The input letter of the subword v. This may be canceling or adding.\n",
    "        :param SubwordDict: A dictionary whose keys are letters and whose values are the first subword that letter appears in.\n",
    "    \n",
    "        :return: a pair (NewState, NewTransition) if the input ('-', InputLetter) does not create an uncancelable pair. \n",
    "        NewTransition is an instance of FSMTransition whose from_state is SourceState and whose to_state is NewState.\n",
    "        If an uncancelable pair is created, this method returns None.\n",
    "        '''\n",
    "        \n",
    "        NewLabel = self._mutable_label(SourceState.label())\n",
    "        NewUncancelableList = []\n",
    "    \n",
    "    \n",
    "        #Subwords w_1 and w_2 have ended.\n",
    "        NewNV = max(NewLabel[10][1], SubwordDict[InputLetter])\n",
    "        NewLabel[10] = (3, NewNV)\n",
    "        \n",
    "        #We will process this input in two cases depending on whether InputLetter is adding or cancelling. The adding case is easiest.\n",
    "    \n",
    "        if NewLabel[11]:\n",
    "            NewLabel[2*NewNV-2].append(InputLetter)\n",
    "            for FirstLettersSet in NewLabel[2*NewNV-1]:\n",
    "                if InputLetter in FirstLettersSet[1]:\n",
    "                    FirstLettersSet[0].add(InputLetter)\n",
    "                FirstLettersSet[1].intersection_update(self.c_map[InputLetter])\n",
    "            NewLabel[2*NewNV-1].append( ({InputLetter},self.c_map[InputLetter]) )\n",
    "            \n",
    "        #We get a  bit flip in this case if NV < 3. \n",
    "            if NewNV < 3:\n",
    "                NewLabel[11] = False\n",
    "                PresentLetterList = NewLabel[0].word_as_list + NewLabel[2].word_as_list + NewLabel[4].word_as_list\n",
    "                PresentLetterSet = set(PresentLetterList)\n",
    "                #Every previously cancelable letter will become uncancelable. \n",
    "                #This will create an uncancelable pair if any of them fail to cancel with one another or with the CancelingLetter.\n",
    "                #We also check whether there are any duplicates among the PresentLetters.\n",
    "                if len(PresentLetterList)>len(PresentLetterSet) or ( not self._test_set_commutation(PresentLetterSet)):\n",
    "                    return(None)\n",
    "                \n",
    "                #Add every remaining cancelable letter into the uncancelable set\n",
    "                NewLabel[8]=NewLabel[8].union(PresentLetterSet)\n",
    "                for letter in PresentLetterSet:\n",
    "                    NewLabel[9].intersection_update(self.c_map[letter])\n",
    "            \n",
    "                #Delete every previously cancelable letter, which appear only in v_1 and v_2\n",
    "                for i in range(0,3):\n",
    "                    NewLabel[2*i] = self.WordGeneratorMachine.word([])\n",
    "                    NewLabel[2*i+1] = []\n",
    "                #The 12th entry of NewState.label() will count the number of ending transitions that have elapsed.\n",
    "                try:\n",
    "                    NewLabel[12] += 1\n",
    "                except IndexError:\n",
    "                    NewLabel.append(1)\n",
    "                NewState = FSMState(self._hashable_label(NewLabel), is_final = (NewLabel[12] == 2))\n",
    "                NewTransition = FSMTransition(SourceState, NewState, ('-', InputLetter))\n",
    "                \n",
    "                \n",
    "                return(NewState, NewTransition)\n",
    "    \n",
    "            #if the bit has not flipped, there is nothing left to do.\n",
    "            try:\n",
    "                NewLabel[12] += 1\n",
    "            except IndexError:\n",
    "                NewLabel.append(1)\n",
    "            NewState = FSMState(self._hashable_label(NewLabel), is_final = (NewLabel[12] == 2))\n",
    "            NewTransition = FSMTransition(SourceState, NewState, ('-', InputLetter))\n",
    "            return (NewState, NewTransition)\n",
    "\n",
    "        #If the InputLetter is canceling, then the increase of NV may have created new uncancelable letters.\n",
    "        NewUncancelableList = []\n",
    "        for i in range (0, NewNV-1):\n",
    "            NewUncancelableList.extend(NewLabel[2*i].word_as_list)\n",
    "            NewLabel[2*i] = self.WordGeneratorMachine.word([])\n",
    "            NewLabel[2*i+1] = []\n",
    "\n",
    "        NewUncancelableSet = set(NewUncancelableList)\n",
    "        RemainingLetterList = NewLabel[0].word_as_list + NewLabel[2].word_as_list + NewLabel[4].word_as_list\n",
    "        RemainingLetterSet = set(RemainingLetterList)\n",
    "\n",
    "        #Check if this creates an uncancelable pair.\n",
    "\n",
    "        if (len(NewUncancelableList) > len(NewUncancelableSet)) or ( not self._test_set_commutation(NewUncancelableSet)) or ( not self._test_set_pair_commutation (NewUncancelableSet, RemainingLetterSet, True) ):\n",
    "            return(None)\n",
    "\n",
    "        #If there is no uncancelable pair, it is also possible to create a bit flip. It is not possible for n_v to be greater than 3, and the InputLetter is a letter of v.\n",
    "        #Therefore, we only check if the InputLetter commutes with and follows every RemainingLetter.\n",
    "        \n",
    "        LettersFollowingAllRemainingLetters = copy.copy(self.alphabet)\n",
    "        for letter in RemainingLetterSet:\n",
    "            LettersFollowingAllRemainingLetters.intersection_update(self.greater_star[letter])\n",
    "        \n",
    "        if InputLetter in LettersFollowingAllRemainingLetters:\n",
    "            #Every RemainingLetter will become uncancelable. Check whether this creates an uncancelable pair.\n",
    "            if (len(RemainingLetterList) > len(RemainingLetterSet) or not self._test_set_commutation(RemainingLetterSet)):\n",
    "                return(None)\n",
    "            \n",
    "            NewLabel[8] = NewLabel[8].union(RemainingLetterSet)\n",
    "            for letter in RemainingLetterSet:\n",
    "                    NewLabel[9].intersection_update(self.c_map[letter])\n",
    "            for i in range(0,4):\n",
    "                NewLabel[2*i] = self.WordGeneratorMachine.word([])\n",
    "                NewLabel[2*i+1] = []\n",
    "                \n",
    "            #the InputLetter becomes the only cancelable letter if it is in subword 3. Otherwise it becomes uncancelable as well.\n",
    "            \n",
    "            if NewNV == 3:\n",
    "                NewLabel[4] = self.WordGeneratorMachine.word([InputLetter])\n",
    "                NewLabel[5].append(({InputLetter}, self.c_map[InputLetter]))\n",
    "                NewLabel[11] = True\n",
    "\n",
    "                try:\n",
    "                    NewLabel[12] += 1\n",
    "                except IndexError:\n",
    "                    NewLabel.append(1)\n",
    "                NewState = FSMState(self._hashable_label(NewLabel), is_final = (NewLabel[12] == 2))\n",
    "                NewTransition = FSMTransition(SourceState, NewState, ('-',InputLetter))\n",
    "                return (NewState, NewTransition)\n",
    "\n",
    "            #The InputLetter becomes uncancellable. We know already that it commutes with every other letter.\n",
    "            NewLabel[8].add(InputLetter)\n",
    "            NewLabel[9].intersection_update(self.c_map[InputLetter])\n",
    "            try:\n",
    "                NewLabel[12] += 1\n",
    "            except IndexError:\n",
    "                NewLabel.append(1)\n",
    "            NewState = FSMState(self._hashable_label(NewLabel), is_final = (NewLabel[12] == 2))\n",
    "            NewTransition = FSMTransition(SourceState, NewState, ('-',InputLetter))\n",
    "            return (NewState, NewTransition)\n",
    "\n",
    "        #If the bit has not flipped, then we process the InputLetter as a canceling letter.\n",
    "        NewLabel = self.process_canceling_letter(NewLabel, InputLetter, SubwordDict)\n",
    "        if NewLabel is None:\n",
    "            return (None)\n",
    "        try:\n",
    "            NewLabel[12] += 1\n",
    "        except IndexError:\n",
    "            NewLabel.append(1)\n",
    "        NewState = FSMState(self._hashable_label(NewLabel), is_final = (NewLabel[12] == 2))\n",
    "        NewTransition = FSMTransition(SourceState, NewState, ('-',InputLetter))\n",
    "        return (NewState, NewTransition)\n",
    "\n",
    "    def _mutable_label(self, HashableLabel:tuple) -> list:\n",
    "        '''\n",
    "        This method takes a hashable label, as described above, and renders it mutable.\n",
    "        '''\n",
    "    \n",
    "        MutableLabel = list(HashableLabel)\n",
    "        \n",
    "        for i in range (0, 4):\n",
    "            MutableLabel[2*i] = self.WordGeneratorMachine.word(HashableLabel[2*i])\n",
    "            NewList = []\n",
    "            for (FirstLetterTuple, PotentialFirstLetterTuple) in HashableLabel[2*i+1]:\n",
    "                NewList.append( (set(FirstLetterTuple), set(PotentialFirstLetterTuple)) )\n",
    "            MutableLabel[2*i+1] = NewList\n",
    "        MutableLabel[8] = set(HashableLabel[8])\n",
    "        MutableLabel[9] = set(HashableLabel[9])\n",
    "        \n",
    "        return(MutableLabel)\n",
    "    \n",
    "    def _hashable_label(self, MutableLabel:list) -> tuple:\n",
    "        '''\n",
    "        This method takes a mutable state label as described above, and renders it hashable.\n",
    "        '''\n",
    "        for i in range (0, 4):\n",
    "            MutableLabel[2*i] = MutableLabel[2*i].word_as_tuple()\n",
    "            NewList = []\n",
    "            #Coerce the first letter data into tuples \n",
    "            for (FirstLetterSet, PotentialFirstLetterSet) in MutableLabel[2*i+1]:\n",
    "                NewList.append( ( tuple(sorted(FirstLetterSet, key = lambda x: self.o_map[x])), tuple(sorted(PotentialFirstLetterSet, key = lambda x: self.o_map[x])) ) )\n",
    "            MutableLabel[2*i+1]=tuple(NewList)\n",
    "        if isinstance(MutableLabel[8], set):\n",
    "            MutableLabel[8] = tuple(sorted(MutableLabel[8], key = lambda x: self.o_map[x]))\n",
    "        if isinstance(MutableLabel[9], set):\n",
    "            MutableLabel[9] = tuple(sorted(MutableLabel[9], key = lambda x: self.o_map[x]))\n",
    "    \n",
    "        return(tuple(MutableLabel))\n",
    "\n",
    "    def _test_set_commutation(self, LetterSet: set) -> bool:\n",
    "        #This method takes as input a set of characters in self.alphabet and checks whether they pairwise commute.\n",
    "        LetterList = sorted(LetterSet, key = lambda x: self.o_map[x])\n",
    "        for i in range(0, len(LetterList)):\n",
    "            #There is no need to include LetterList[i] in the set of letters it commutes with, because LetterSet is a set. We will never test its commutation against itself.\n",
    "            IthLetterNeighbors = self.c_map[LetterList[i]]\n",
    "            for j in range(i+1, len(LetterList)):\n",
    "                if j not in IthLetterNeighbors:\n",
    "                    return(False)\n",
    "        return(True)\n",
    "\n",
    "    def _test_set_pair_commutation(self, FirstLetterSet: set, SecondLetterSet: set, AllDistinct = False) -> bool:\n",
    "        #This method takes two sets of characters in self.alphabet and checks whether each letter in the first set commutes with each letter in the second set.\n",
    "        #Optionally, it tests whether the two sets are disjoint. In our use cases, an uncancelable letter appearing in a word must be preceded by another letter that creates an uncancelable pair.\n",
    "        #Therefore, AllDistinct = True will sometimes serve to prune states that we will not use.\n",
    "\n",
    "        if AllDistinct and (FirstLetterSet.intersection(SecondLetterSet) != set()):\n",
    "            return(False)\n",
    "        for LetterPair in product(FirstLetterSet, SecondLetterSet):\n",
    "            if not LetterPair[0] in (self.c_map[LetterPair[1]].union({LetterPair[1]})):\n",
    "                return(False)\n",
    "        return(True)\n",
    "       \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9425dfc5-6368-42a4-934a-77636b243a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RipsHorosphereGenerator:\n",
    "    def __init__(self, commutation_dict: dict[str, set], order_dict: dict[str, int], ray: list[str]):\n",
    "        self.c_map = commutation_dict\n",
    "        self.o_map = order_dict\n",
    "        self.alphabet = set().union(letter for letter in self.o_map)\n",
    "        self.ray = ray\n",
    "        fsm_gen = Rips_FSM_Generator(self.c_map, self.o_map, self.ray)\n",
    "        self.suffix_generator = fsm_gen.shortlex_suffix_machine\n",
    "        self.geodesic_suffix_machine = fsm_gen.geodesic_suffix_machine\n",
    "        self.ray_excluder = fsm_gen.__FSM_Generator_first_letter_excluder(set(ray))\n",
    "        self.word_gen = WordGenerator(self.c_map, self.o_map)\n",
    "\n",
    "    def get_all_length_n_suffixes(self, n:int) -> list:\n",
    "        \"\"\"\n",
    "        Finds all suffixes of length at most n by a BFS.\n",
    "\n",
    "        :param n: The depth with which the BFS will be conducted.\n",
    "        :return: A list of all shortlex suffixes of length at most n, formatted as instances of the Word class.\n",
    "        \"\"\"\n",
    "        \n",
    "        n += 1\n",
    "        origin = self.suffix_generator.initial_states()[0]\n",
    "\n",
    "        # All elements of the frontier are of the form (FSMState, current depth, word)\n",
    "        frontier = [(origin, 0, self.word_gen.word([]))]\n",
    "        # We will add the words to words_out\n",
    "        words_out = []\n",
    "\n",
    "        while frontier:\n",
    "            state, depth, word = frontier.pop(0)\n",
    "            # Only go to depth n\n",
    "            if depth == n:\n",
    "                continue\n",
    "\n",
    "            words_out.append(word)\n",
    "\n",
    "            # Continue traversing\n",
    "            for transition in self.suffix_generator.iter_transitions(state):\n",
    "                frontier.append(transition.to_state, depth+1, self.word_gen.word(word.word_as_list + next_letter))\n",
    "\n",
    "        return words_out\n",
    "\n",
    "    def calculate_same_length_rips_adjacencies(self, suffix:Word) -> list:\n",
    "        \"\"\"\n",
    "        Given a shortlex suffix, find all suffixes of the same length on the same horosphere that are at distance 2.\n",
    "\n",
    "        :param suffix: A shortlex suffix.\n",
    "        :return: The list of all suffixes of the same length as suffix that are at distance 2 from suffix.\n",
    "        \"\"\"\n",
    "\n",
    "        SuffixMachineState = self.suffix_generator.process(suffix.word_as_list)\n",
    "        \n",
    "        if not SuffixMachineState[0]:\n",
    "            raise ValueError('The input is not a shortlex suffix')\n",
    "        \n",
    "        # Edge case: empty string \"\". There are no other length-0 words \n",
    "        if len(suffix) == 0:\n",
    "            return []\n",
    "\n",
    "        GeodesicSuffixMachineState = self.geodesic_suffix_machine.process(suffix.word_as_list)[1]\n",
    "        adjacencies = []\n",
    "        \n",
    "        for last_letter in GeodesicSuffixMachineState.label()[0]:\n",
    "\n",
    "            # Remove the last instance of last_letter from the word.\n",
    "            reversed_word = suffix.word_as_list[::-1]\n",
    "            deleted_word = (reversed_word[0:reversed_word.index(last_letter):]+reversed_word[reversed_word.index(last_letter)+1::])[::-1]\n",
    "\n",
    "            deleted_word_state = self.geodesic_suffix_machine.process(deleted_word.word_as_list)[1]\n",
    "\n",
    "            #The valid letters are those that will not cancel, will not join the prefix, and are not last_letter itself\n",
    "            connecting_letters = self.alphabet.difference(set(deleted_word_state.label()[0]).union(set(deleted_word_state.label()[1])).union({last_letter}))\n",
    "\n",
    "            # Lengthen the reduced word by its geodesic legal next letters to get all same length adjacent suffixes\n",
    "            for letter in connecting_letters:\n",
    "                adjacencies.append(deleted_word.copy().shortlex_append(letter))\n",
    "\n",
    "        return adjacencies\n",
    "\n",
    "    def calculate_different_length_rips_adjacencies(self, suffix: Word, mode:int) -> list:\n",
    "        \"\"\"\n",
    "        Given a suffix, this method finds all suffixes that are 1 letter shorter so that the related words are at distance 2.\n",
    "\n",
    "        :param suffix: A shortlex suffix.\n",
    "        :param mode: either 0 or 1. The prefix letter to be deleted or added is self.ray[mode].\n",
    "        :return: The list of all such suffixes.\n",
    "        \"\"\"\n",
    "\n",
    "        suffix_state = self.suffix_generator.process(suffix.word_as_list)[1]\n",
    "\n",
    "        adjacencies = []\n",
    "\n",
    "        #Edge case: suffixes of length 0.\n",
    "        #There are no suffixes of negative length.\n",
    "        if len(suffix) == 0:\n",
    "            return adjacencies\n",
    "\n",
    "        GeodesicSuffixMachineState = self.geodesic_suffix_machine.process(suffix.word_as_list)[1]\n",
    "\n",
    "        for last_letter in GeodesicSuffixMachineState.label()[0]:\n",
    "\n",
    "            # Remove the last instance of last_letter from the word.\n",
    "            reversed_word = suffix.word_as_list[::-1]\n",
    "            deleted_word = (reversed_word[0:reversed_word.index(last_letter):]+reversed_word[reversed_word.index(last_letter)+1::])[::-1]\n",
    "\n",
    "            #Check whether to keep this word.\n",
    "            if self.ray[mode] in set(self.ray_excluder.process(deleted_word.word_as_list)[1].label()):\n",
    "                adjacencies.append(deleted_word)\n",
    "                \n",
    "        return adjacencies\n",
    "\n",
    "    def calculate_rips_adjacencies(self, suffix:Word, BusemannValue: int) -> list:\n",
    "        \"\"\"\n",
    "        Use \"calculate_same_length_rips_adjacencies\" and \"calculate_different_length_rips_adj\" to find all adjacent words which are at most as long as suffix.\n",
    "\n",
    "        :param suffix: A shortlex suffix.\n",
    "        :return: All adjacent suffixes at most as long as \"suffix\".\n",
    "        \"\"\"\n",
    "\n",
    "        adjacencies = []\n",
    "\n",
    "        mode = 1-((BusemannValue - len(suffix))%2)\n",
    "        \n",
    "        adjacencies.extend(self.calculate_same_length_rips_adjacencies(suffix))\n",
    "        adjacencies.extend(self.calculate_different_length_rips_adjacencies(suffix, mode))\n",
    "        return adjacencies\n",
    "\n",
    "    def calculate_horosphere_edges(self, suffix_list: list, BusemannValue: int) -> list:\n",
    "        \"\"\"\n",
    "        Calculate the set of edges from entries of suffix_list to shorter suffixes.\n",
    "\n",
    "        :param suffix_list: A list of suffixes.\n",
    "        :param BusemannValue: Value of the Busemann function for the horosphere.\n",
    "        :return: A list of all pairs of suffixes whose corresponding words are at distance 2, \n",
    "        such that the first is an entry of suffix_list and the second is no longer than the first.\n",
    "        \"\"\"\n",
    "\n",
    "        edges = []\n",
    "\n",
    "        for suffix in suffix_list:\n",
    "            edges.append( (str(suffix), str(newsuffix)) for newsuffix in self.calculate_rips_adjacencies(suffix, BusemannValue) )\n",
    "        return(edges)\n",
    "        \n",
    "    def horosphere_as_networkx(self, length: int, BusemannValue: int):\n",
    "        suffixes = self.get_all_length_n_suffixes(length)\n",
    "        print(f\"Suffixes of length {length} calculated: \\n\\t\\t {len(words)} words found\")\n",
    "        edges = self.calculate_horosphere_edges(suffixes, BusemannValue)\n",
    "        print(f\"Words processing completed: \\n\\t\\t {len(words)} words processed\")\n",
    "\n",
    "        G = networkx.Graph()\n",
    "        G.add_edges_from(processed_edges)\n",
    "        print(f\"Length {length} Horosphere generated: \\n\\t\\t {G}\")\n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ed42d34-f9f1-4350-b012-779cf3820919",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivergenceHorosphereGenerator:\n",
    "    def __init__(self, commutation_dict: dict[str, set], order_dict: dict[str, int], ray: list[str]):\n",
    "        self.c_map = commutation_dict\n",
    "        self.o_map = order_dict\n",
    "        self.alphabet = set().union(letter for letter in self.o_map)\n",
    "        self.ray = ray\n",
    "        fsm_gen = Divergence_FSM_Generator(self.c_map, self.o_map, self.ray)\n",
    "        self.horocyclic_suffix_machine_1234 = fsm_gen.horocyclic_suffix_machine_1234()\n",
    "        self.horocyclic_suffix_machine_1256 = fsm_gen.horocyclic_suffix_machine_1256()\n",
    "        self.shortlex_machine = fsm_gen._Rips_FSM_Generator__shortlex_machine()\n",
    "        self.geodesic_machine = fsm_gen._Rips_FSM_Generator__geodesic_machine()\n",
    "        self.geodesic_suffix_machine = fsm_gen.geodesic_suffix_machine()\n",
    "        self.word_gen = WordGenerator(self.c_map, self.o_map)\n",
    "\n",
    "        #These dictionaries will keep track of which letters appear in which subwords of horocyclic suffixes. \n",
    "        SubwordDict1234 = {}\n",
    "        SubwordDict1256 = {}\n",
    "        SubwordDictDifferentLength = {}\n",
    "        #The letters that commute with and precede both ray letters appear first in w_1\n",
    "        for letter in self.c_map[self.ray[0]].intersection(fsm_gen.lesser_star[self.ray[1]]):\n",
    "            SubwordDict1234[letter] = 1\n",
    "            SubwordDict1256[letter] = 1\n",
    "            SubwordDictDifferentLength[letter] = 1\n",
    "        #The letters that commute with both ray letters and precede only the first appear first in w_2\n",
    "        for letter in fsm_gen.lesser_star[self.ray[0]].intersection(fsm_gen.greater_star[self.ray[1]]):\n",
    "            SubwordDict1234[letter] = 2\n",
    "            SubwordDict1256[letter] = 2\n",
    "            SubwordDictDifferentLength[letter] = 2\n",
    "        #For words of the form w_1w_2w_3w_4, the letters that commute with and precede the second ray letter, but do not commute with the first, appear in w_3.\n",
    "        for letter in fsm_gen.lesser_star[self.ray[1]].difference(self.c_map[self.ray[0]]):\n",
    "            SubwordDict1234[letter] = 3\n",
    "        #All the rest appear only in w_4\n",
    "        for letter in fsm_gen.alphabet.difference(fsm_gen.lesser_star[self.ray[1]].union(fsm_gen.lesser_star[self.ray[0]].intersection(self.c_map[self.ray[1]]))):\n",
    "            SubwordDict1234[letter] = 4\n",
    "        #For words of the form w_1w_2w_5w_6, the letters that commute with and precede the first ray letter, but do not commute with the second, appear in w_5\n",
    "        for letter in fsm_gen.lesser_star[self.ray[0]].difference(self.c_map[self.ray[1]]):\n",
    "            SubwordDict1256[letter] = 3\n",
    "        #All the rest appear only in w_6\n",
    "        for letter in fsm_gen.alphabet.difference(fsm_gen.lesser_star[self.ray[0]].union(fsm_gen.lesser_star[self.ray[1]].intersection(self.c_map[self.ray[0]]))):\n",
    "            SubwordDict1256[letter] = 4\n",
    "        #For pairs of words of different length, every other letter will be in subword 3.\n",
    "        for letter in self.alphabet:\n",
    "            try:\n",
    "                SubwordDictDifferentLength[letter]\n",
    "            except KeyError:\n",
    "                SubwordDictDifferentLength[letter] = 3\n",
    "\n",
    "        self.same_length_edge_checker1234 = fsm_gen.horocyclic_edge_checker(SubwordDict1234)\n",
    "        self.same_length_edge_checker1256 = fsm_gen.horocyclic_edge_checker(SubwordDict1256)\n",
    "        self.different_length_edge_checker = fsm_gen.horocyclic_edge_checker(SubwordDictDifferentLength)\n",
    "        \n",
    "        self.clique_dimension = self._determine_clique_dimension_recursive(0, self.alphabet)\n",
    "\n",
    "    def _determine_clique_dimension_recursive(self, running_total: int, allowable_set:set) -> int:\n",
    "        '''\n",
    "        A recursive method to determine the clique dimension of the defining graph.\n",
    "\n",
    "        :param running_total: the number of letters already in the clique.\n",
    "        :param allowable_set: the collection of letters commuting with those already in the clique.\n",
    "        :return: the maximum size of a clique containing the letters already included.\n",
    "        '''\n",
    "\n",
    "        if allowable_set == set():\n",
    "            return running_total\n",
    "\n",
    "        n = running_total\n",
    "        \n",
    "        for letter in allowable_set:\n",
    "            n = max(n, self._determine_clique_dimension_recursive(running_total+1, allowable_set.intersection(self.c_map[letter])))\n",
    "        return(n)\n",
    "\n",
    "    def get_all_length_n_horocyclic_suffixes(self, n:int, mode:bool) -> list:\n",
    "        '''\n",
    "        Generate the list of horocyclic suffixes of length n or less.\n",
    "\n",
    "        :param mode: False if the value of the Busemann Function is even, True if odd.\n",
    "\n",
    "        :return: A list of all horocyclic suffixes for the desired value of the Busemann Function of up to length n.\n",
    "        '''\n",
    "        \n",
    "        HorocyclicSuffixList = []\n",
    "        #EvenList = []\n",
    "        #OddList = []\n",
    "        Frontier = []\n",
    "\n",
    "        if mode:\n",
    "            EvenLengthGenerator = self.horocyclic_suffix_machine_1234\n",
    "            OddLengthGenerator = self.horocyclic_suffix_machine_1256\n",
    "        else:\n",
    "            EvenLengthGenerator = self.horocyclic_suffix_machine_1256\n",
    "            OddLengthGenerator = self.horocyclic_suffix_machine_1234\n",
    "        \n",
    "        #EvenList.append(self.word_gen.horocyclic_word([[], [], [], []]))\n",
    "        NewWord = self.word_gen.horocyclic_word([[], [], [], []], mode)\n",
    "        HorocyclicSuffixList.append(NewWord)\n",
    "        Frontier.append((EvenLengthGenerator.initial_states()[0], 0, NewWord))\n",
    "        \n",
    "        #Edge case: n==0\n",
    "\n",
    "        if n == 0:\n",
    "            return HorocyclicSuffixList\n",
    "\n",
    "        for transition in OddLengthGenerator.transitions(OddLengthGenerator.initial_states()[0]):\n",
    "            NextStateLabel = transition.to_state.label()\n",
    "            if NextStateLabel[0]:\n",
    "                #If NextStateLabel[0] is 1, that means that the letter is not in w_1 or w_2. \n",
    "                #In particular, the label is of the form (1, (( int, SubwordState), (LetterExcluderState) ) ) where int is 0 for the third subword or 1 for the fourth.\n",
    "                SubwordList = [[], [], [], []]\n",
    "                SubwordList[2+NextStateLabel[1][0].label()[0]] = [transition.word_in]\n",
    "            else:\n",
    "                #If NextStateLabel[0] is 0, that means that the letter is in w_1 or w_2.\n",
    "                #In particular, the label is of the form (0, (int, SubwordState)) where int is 0 for the first subword or 1 for the second.\n",
    "                SubwordList = [[], [], [], []]\n",
    "                SubwordList[NextStateLabel[1][0]] = [transition.word_in]\n",
    "            NewWord = self.word_gen.horocyclic_word(SubwordList, not mode)\n",
    "            HorocyclicSuffixList.append(NewWord)\n",
    "            #OddList.append(ResultingWord)\n",
    "            Frontier.append((transition.to_state, 1, NewWord))\n",
    "\n",
    "        #We will lengthen words 2 letters at a time.\n",
    "        while Frontier:\n",
    "            state, depth, word = Frontier.pop(0)\n",
    "            if depth > n-2:\n",
    "                continue\n",
    "            if depth%2:\n",
    "                for FirstTransition in OddLengthGenerator.transitions(state):\n",
    "                    for SecondTransition in OddLengthGenerator.transitions(FirstTransition.to_state):\n",
    "                        NewWord = word.copy()\n",
    "\n",
    "                        #Append the first letter to the relevant subword\n",
    "                        if FirstTransition.to_state.label()[0]:\n",
    "                            NewWord.append(FirstTransition.word_in, 2+FirstTransition.to_state.label()[1][0].label()[0])\n",
    "                        else:\n",
    "                            NewWord.append(FirstTransition.word_in, FirstTransition.to_state.label()[1][0])\n",
    "                            \n",
    "                        #Append the second letter to the relevant subword.\n",
    "                        if SecondTransition.to_state.label()[0]:\n",
    "                            NewWord.append(SecondTransition.word_in, 2+SecondTransition.to_state.label()[1][0].label()[0])\n",
    "                        else:\n",
    "                            NewWord.append(SecondTransition.word_in, SecondTransition.to_state.label()[1][0])\n",
    "                            \n",
    "                        HorocyclicSuffixList.append(NewWord)\n",
    "                        Frontier.append((SecondTransition.to_state, depth+2, NewWord))\n",
    "                        #OddList.append(NewWord)\n",
    "            else:\n",
    "                for FirstTransition in EvenLengthGenerator.transitions(state):\n",
    "                    for SecondTransition in EvenLengthGenerator.transitions(FirstTransition.to_state):\n",
    "                        NewWord = word.copy()\n",
    "\n",
    "                        #Append the first letter to the relevant subword\n",
    "                        if FirstTransition.to_state.label()[0]:\n",
    "                            NewWord.append(FirstTransition.word_in, 2+FirstTransition.to_state.label()[1][0].label()[0])\n",
    "                        else:\n",
    "                            NewWord.append(FirstTransition.word_in, FirstTransition.to_state.label()[1][0])\n",
    "                            \n",
    "                        #Append the second letter to the relevant subword.\n",
    "                        if SecondTransition.to_state.label()[0]:\n",
    "                            NewWord.append(SecondTransition.word_in, 2+SecondTransition.to_state.label()[1][0].label()[0])\n",
    "                        else:\n",
    "                            NewWord.append(SecondTransition.word_in, SecondTransition.to_state.label()[1][0])\n",
    "                            \n",
    "                        HorocyclicSuffixList.append(NewWord)\n",
    "                        Frontier.append((SecondTransition.to_state, depth+2, NewWord))\n",
    "                        #EvenList.append(NewWord)\n",
    "\n",
    "        return HorocyclicSuffixList\n",
    "            \n",
    "    def calculate_same_length_divergence_adjacencies(self, HorocyclicSuffix:HorocyclicWord) ->list:\n",
    "        '''\n",
    "        Given a horocyclic suffix, find all horocyclic suffixes of the same length on the same horosphere such that there is an edge between the two in the divergence graph. \n",
    "        \n",
    "        :param HorocyclicSuffix: A horocyclic suffix.\n",
    "        :return: The list of all horocyclic suffixes of the same length as HorocyclicSuffix such that the two have close successors.\n",
    "        '''\n",
    "\n",
    "        BacktrackedWords = []\n",
    "        CandidateList = []\n",
    "        \n",
    "        #Forbidding loops in the graph.\n",
    "        FinishedWords = [HorocyclicSuffix]\n",
    "        \n",
    "        Adjacencies = []\n",
    "\n",
    "        #We construct the list of horocyclic suffixes of the same length and at distance at most self.clique_dimension away.\n",
    "        #We begin by deleting letters from HorocyclicSuffix\n",
    "\n",
    "        #Edge case: HorocyclicSuffix is short enough that it backtracks all the way to the identity.\n",
    "        if len(HorocyclicSuffix) <self.clique_dimension:\n",
    "            BacktrackedWords = [self.word_gen.horocyclic_word([[],[],[],[]], HorocyclicSuffix.mode)]\n",
    "        else:\n",
    "            BacktrackedWords = self._backtracking_recursive(HorocyclicSuffix, self.clique_dimension, self.shortlex_machine.initial_states()[0])\n",
    "\n",
    "        #We can follow this word by any geodesic word, as long as the result is still a suffix. This will be be potentially highly non-unique, but it is not obvious how to avoid repetition\n",
    "        for word in BacktrackedWords:\n",
    "            CandidateList.extend(self._geodesic_successor_horocyclic_suffixes(word, min(len(HorocyclicSuffix),self.clique_dimension), self.geodesic_suffix_machine.process(word.word_as_list)[1]))\n",
    "\n",
    "        while len(CandidateList) > 0:\n",
    "            CurrentCandidate = CandidateList.pop(0)\n",
    "            if CurrentCandidate in FinishedWords:\n",
    "                continue\n",
    "\n",
    "            #The edge checker machine wants an input tape that consists of pairs of characters.\n",
    "            InputList = list(zip(HorocyclicSuffix.word_as_list+['-'], CurrentCandidate.word_as_list+['-']))\n",
    "            \n",
    "            \n",
    "            if HorocyclicSuffix.mode:\n",
    "                InputAccepted, EndState = self.same_length_edge_checker1234.process(InputList)[:2]\n",
    "            else:\n",
    "                InputAccepted, EndState = self.same_length_edge_checker1256.process(InputList)[:2]\n",
    "            if not InputAccepted:\n",
    "                FinishedWords.append(CurrentCandidate)\n",
    "                continue\n",
    "\n",
    "            #The same length edge checker only tells us that no non-cancelable pair has been created.\n",
    "            #To check whether the two have close successors, we need to check whether there is an infinite alternation of some pair of letters as described in Proposition 5.2.10\n",
    "\n",
    "            CancelingWord = EndState.label()[6]\n",
    "            #If the cancelable letters were part of the second word (CurrentCandidate) then it is the first word (HorocyclicSuffix) that needs to be elongated to achieve full cancelation\n",
    "            if EndState.label()[11]:\n",
    "                ElongatedWord = HorocyclicSuffix.word_as_list + list(CancelingWord)\n",
    "                NonElongatedWord = CurrentCandidate.word_as_list\n",
    "            #Otherwise, it is CurrentCandidate that needs to be elongated.\n",
    "            else:\n",
    "                ElongatedWord = CurrentCandidate.word_as_list + list(CancelingWord)\n",
    "                NonElongatedWord = HorocyclicSuffix.word_as_list\n",
    "                \n",
    "            if HorocyclicSuffix.mode:\n",
    "                relevant_suffix_machine = self.horocyclic_suffix_machine_1234\n",
    "            else:\n",
    "                relevant_suffix_machine = self.horocyclic_suffix_machine_1256\n",
    "            ElongatedState = relevant_suffix_machine.process(ElongatedWord)[1]\n",
    "            NonElongatedState = relevant_suffix_machine.process(NonElongatedWord)[1]\n",
    "            \n",
    "            LettersCommutingWithClique = set(EndState.label()[9])\n",
    "            #Check whether any of these letters is permitted by both the above states.\n",
    "\n",
    "            print('Processing pair ', HorocyclicSuffix.word_as_list, CurrentCandidate.word_as_list)\n",
    "            print('The elongated word is ', ElongatedWord, ' and the non-elongated word is ', NonElongatedWord)\n",
    "            print('The state of the elongated word is ', ElongatedState.label())\n",
    "            print('Its outgoing transitions are ', relevant_suffix_machine.transitions(ElongatedState))\n",
    "            \n",
    "            #Recall that transition.word_in outputs a list containing the label of the transition, not the label itself.\n",
    "            LettersAcceptedFromElongatedState = {str for str in transition.word_in for transition in relevant_suffix_machine.iter_transitions(ElongatedState)}\n",
    "            #ElongatedTransitionDict = relevant_suffix_machine.transition_dict(ElongatedState)\n",
    "            LettersAcceptedFromNonElongatedState = {str for str in transition.word_in for transition in relevant_suffix_machine.iter_transitions(NonElongatedState)}\n",
    "            #NonElongatedTransitionDict = relevant_suffix_machine.transition_dict(NonElongatedState)\n",
    "        \n",
    "            for letter in LettersCommutingWithClique:\n",
    "                if letter in LettersAcceptedFromElongatedState.intersection(LettersAcceptedFromNonElongatedState) and LettersCommutingWithClique.difference(self.c_map[letter].union({letter})) != set():\n",
    "                    Adjacencies.append(CurrentCandidate)\n",
    "                    break\n",
    "            FinishedWords.append(CurrentCandidate)\n",
    "                    \n",
    "        return Adjacencies\n",
    "\n",
    "    def calculate_shorter_divergence_adjacencies(self, HorocyclicSuffix:HorocyclicWord) ->list:\n",
    "        '''\n",
    "        Given a horocyclic suffix, find all shorter horocyclic on the same horosphere such that there is an edge between the two in the divergence graph. \n",
    "        \n",
    "        :param HorocyclicSuffix: A horocyclic suffix.\n",
    "        :return: The list of all horocyclic suffixes of shorter than HorocyclicSuffix such that the two have close successors.\n",
    "        '''\n",
    "\n",
    "        Adjacencies = []\n",
    "        \n",
    "        if HorocyclicSuffix[3] != []:\n",
    "            return Adjacencies\n",
    "\n",
    "        for letter in HorocyclicSuffix[4]:\n",
    "            if not letter in self.c_map[self.ray[1-int(HorocyclicSuffix.mode)]]:\n",
    "                return Adjacencies\n",
    "        \n",
    "        BacktrackedWords = []\n",
    "        CandidateList = []\n",
    "        FinishedWords = []\n",
    "\n",
    "        #This list will keep track of the letters to add to the shorter word\n",
    "        ExtensionList = []\n",
    "        for length in range(0, self.clique_dimension):\n",
    "            if HorocyclicSuffix.mode ^ length%2:\n",
    "                ExtensionList.append(self.ray[0])\n",
    "            else:\n",
    "                ExtensionList.append(self.ray[1])\n",
    "        \n",
    "        if HorocyclicSuffix[4] == []:\n",
    "            #If so, then every letter of HorocyclicSuffix commutes with both self.ray[0] and self.ray[1], so that they all commute with one another.\n",
    "            #Therefore, these words backtrack all the way to the identity.\n",
    "            CandidateList = self.get_all_length_n_horocyclic_suffixes(len(HorocyclicSuffix)-1, not (HorocyclicSuffix.mode ^ (len(HorocyclicSuffix)%2)))\n",
    "\n",
    "        else:\n",
    "            #In this case, the only shorter words that HorocyclicSuffix can be adjacent to are words that are 1 letter shorter. These must all be of the opposite form to HorocyclicSuffix\n",
    "            if len(HorocyclicSuffix) < self.clique_dimension:\n",
    "                BacktrackedWords = [self.word_gen.horocyclic_word([[],[],[],[]], not HorocyclicSuffix.mode)]\n",
    "            else:\n",
    "                StartingWord = self._switch_form_special_case(HorocyclicSuffix)\n",
    "                BacktrackedWords = self._backtracking_recursive(StartingWord, self.clique_dimension, self.shortlex_machine.initial_states()[0])\n",
    "                                \n",
    "            for word in BacktrackedWords:\n",
    "                CandidateList.extend(self._geodesic_successor_horocyclic_suffixes(word, min(len(HorocyclicSuffix),self.clique_dimension)), self.geodesic_suffix_machine.process(word.word_as_list)[1])\n",
    "            \n",
    "        while CandidateList:\n",
    "            CurrentCandidate = CandidateList.pop(0)\n",
    "            if CurrentCandidate in FinishedWords:\n",
    "                continue\n",
    "\n",
    "            CandidateInput = CurrentCandidate[0] + CurrentCandidate[1] + CurrentCandidate[2] + ExtensionList[0:len(HorocyclicSuffix)-len(CurrentCandidate):] + CurrentCandidate[3]\n",
    "            InputList = list(zip(HorocyclicSuffix.word_as_list+['-'], CandidateInput+['-']))\n",
    "\n",
    "            EndState = self.different_length_edge_checker.process(InputList)\n",
    "            if not EndState[0]:\n",
    "                FinishedWords.append(CurrentCandidate)\n",
    "                continue\n",
    "\n",
    "            #The same length edge checker only tells us that no non-cancelable pair has been created.\n",
    "            #To check whether the two have close successors, we need to check whether there is an infinite alternation of some pair of letters as described in Proposition 5.2.10\n",
    "\n",
    "            CancelingWord = EndState.label()[4]\n",
    "             \n",
    "            if HorocyclicSuffix.mode:\n",
    "                if EndState.label()[11]:\n",
    "                    HorocyclicState = self.horocyclic_suffix_machine_1234.process(HorocyclicSuffix.word_as_list + list(CancelingWord))[1]\n",
    "                    HorocyclicTransitionDict = self.horocyclic_suffix_machine_1234.transition_dict(HorocyclicState)\n",
    "                else:\n",
    "                    HorocyclicState = self.horocyclic_suffix_machine_1234.process(HorocyclicSuffix.word_as_list)[1]\n",
    "                    HorocyclicTransitionDict = self.horocyclic_suffix_machine_1234.transition_dict(HorocyclicState)\n",
    "            else:\n",
    "                if EndState.label()[11]:\n",
    "                    HorocyclicState = self.horocyclic_suffix_machine_1256.process(HorocyclicSuffix.word_as_list + list(CancelingWord))[1]\n",
    "                    HorocyclicTransitionDict = self.horocyclic_suffix_machine_1256.transition_dict(HorocyclicState)\n",
    "                else:\n",
    "                    HorocyclicState = self.horocyclic_suffix_machine_1256.process(HorocyclicSuffix.word_as_list)[1]\n",
    "                    HorocyclicTransitionDict = self.horocyclic_suffix_machine_1256.transition_dict(HorocyclicState)\n",
    "\n",
    "            if CurrentCandidate.mode:\n",
    "                if EndState.label()[11]:\n",
    "                    CandidateState = self.horocyclic_suffix_machine_1234.process(CurrentCandidate.word_as_list)[1]\n",
    "                    CandidateTransitionDict = self.horocyclic_suffix_machine_1234.transition_dict(CandidateState)\n",
    "                else:\n",
    "                    CandidateState = self.horocyclic_suffix_machine_1234.process(CurrentCandidate.word_as_list+ list(CancelingWord))[1]\n",
    "                    CandidateTransitionDict = self.horocyclic_suffix_machine_1234.transition_dict(CandidateState)\n",
    "            else:\n",
    "                if EndState.label()[11]:\n",
    "                    CandidateState = self.horocyclic_suffix_machine_1256.process(CurrentCandidate.word_as_list)[1]\n",
    "                    CandidateTransitionDict = self.horocyclic_suffix_machine_1256.transition_dict(CandidateState)\n",
    "                else:\n",
    "                    CandidateState = self.horocyclic_suffix_machine_1256.process(CurrentCandidate.word_as_list+ list(CancelingWord))[1]\n",
    "                    CandidateTransitionDict = self.horocyclic_suffix_machine_1256.transition_dict(CandidateState)\n",
    "\n",
    "            LettersCommutingWithClique = set(EndState.label()[9])\n",
    "            #Check whether any of these letters is permitted by both the above states.\n",
    "        \n",
    "            for letter in LettersCommutingWithClique:\n",
    "                #Check if this letter can be written after both words\n",
    "                try:\n",
    "                    HorocyclicTransitionDict[letter]\n",
    "                    CandidateTransitionDict[letter]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                #Check if there is another letter in the alphabet which does not commute with the given letter\n",
    "                if LettersCommutingWithClique.difference(self.c_map[letter].union({letter})) != set():\n",
    "                    Adjacencies.append(CurrentCandidate)\n",
    "                    break\n",
    "            FinishedWords.append(CurrentCandidate)\n",
    "                    \n",
    "        return Adjacencies\n",
    "        \n",
    "    def calculate_divergence_adjacencies(self, HorocyclicSuffix:HorocyclicWord) -> list:\n",
    "        \"\"\"\n",
    "        Use \"calculate_same_length_divergence_adjacencies\" and \"calculate_shorter_divergence_adjacencies\" to find all adjacent words which are at most as long as suffix.\n",
    "\n",
    "        :param HorocyclicSuffix: A horocyclic suffix.\n",
    "        :return: All adjacent suffixes at most as long as \"suffix\".\n",
    "        \"\"\"\n",
    "\n",
    "        adjacencies = []\n",
    "        \n",
    "        adjacencies.extend(self.calculate_same_length_divergence_adjacencies(HorocyclicSuffix))\n",
    "        adjacencies.extend(self.calculate_different_length_rips_adjacencies(HorocyclicSuffix))\n",
    "        \n",
    "        return adjacencies\n",
    "\n",
    "    def calculate_divergence_horosphere_edges(self, HorocyclicSuffix_list: list) -> list:\n",
    "        \"\"\"\n",
    "        Calculate the set of edges from entries of suffix_list to shorter suffixes.\n",
    "\n",
    "        :param HorocyclicSuffix_list: A list of horocyclic suffixes.\n",
    "        :return: A list of all pairs of horocyclic suffixes whose corresponding words have close successors for all time \n",
    "        such that the first is an entry of HorocyclicSuffix_list and the second is no longer than the first.\n",
    "        \"\"\"\n",
    "\n",
    "        edges = []\n",
    "\n",
    "        for suffix in HorocyclicSuffix_list:\n",
    "            edges.append( (str(suffix), str(newsuffix)) for newsuffix in self.calculate_divergence_adjacencies(suffix) )\n",
    "        return(edges)\n",
    "        \n",
    "    def horosphere_as_networkx(self, length: int, BusemannValue: int):\n",
    "        suffixes = self.get_all_length_n_horocyclic_suffixes(length, bool(BusemannValue % 2))\n",
    "        print(f\"Suffixes of length {length} calculated: \\n\\t\\t {len(suffixes)} words found\")\n",
    "        edges = self.calculate_divergence_horosphere_edges(suffixes)\n",
    "        print(f\"Words processing completed: \\n\\t\\t {len(suffixes)} words processed\")\n",
    "\n",
    "        G = networkx.Graph()\n",
    "        G.add_edges_from(processed_edges)\n",
    "        print(f\"Length {length} Horosphere generated: \\n\\t\\t {G}\")\n",
    "        return G\n",
    "\n",
    "    def _backtracking_recursive(self, word:HorocyclicWord, StepCount:int, ShortlexState:FSMState) -> list:\n",
    "        '''\n",
    "        Recursively find all horocyclic suffixes word' so that, as geodesic words word=word' + tail, where tail is a shortlex word StepCount letters long.\n",
    "        The assumption that tail is shortlex is only relevant to make the outputs unique.\n",
    "\n",
    "        :param word: the word that has been reached so far.\n",
    "        :param StepCount: the number of backtracking steps that still remain.\n",
    "        :param ShortlexState: the current state in the shortlex machine \n",
    "        :return: a list without repetition of the HorocyclicWords word' as above.\n",
    "        '''\n",
    "\n",
    "        if StepCount == 0:\n",
    "            return([word])\n",
    "\n",
    "        ResultingWords = []\n",
    "        #We backtrack by the letters that are both final letters of word and still allowed by the shortlex state.\n",
    "        LastLetters = set(self.geodesic_machine.process(word.word_as_list)[1].label())\n",
    "        for transition in self.shortlex_machine.transitions(ShortlexState):\n",
    "            if transition.word_in in LastLetters:\n",
    "                for i in reversed(range(0,4)):\n",
    "                    if transition.word_in in set(word[i]):\n",
    "                        NewSubwordList = word.SubwordList\n",
    "                        ReversedSubword = word.SubwordList[i][::-1]\n",
    "                        DeletedSubword = (ReversedSubword[0:ReversedSubword.index(transition.word_in):]+ReversedSubword[ReversedSubword.index(transition.word_in)+1::])[::-1]\n",
    "                        NewSubwordList[i] = DeletedSubword\n",
    "                        NewWord = self.word_gen.horocyclic_word(NewSubwordList, word.mode)\n",
    "                        break\n",
    "                ResultingWords.extend(self._backtracking_recursive(NewWord, StepCount-1, transition.to_state))\n",
    "        return ResultingWords\n",
    "\n",
    "    def _geodesic_successor_horocyclic_suffixes(self, word:HorocyclicWord, StepCount:int, GeodesicSuffixState:FSMState) -> list:\n",
    "        '''\n",
    "        Recursively find all horocyclic suffixes word' that are StepCount letters longer than word, such that word' is a geodesic successor to word.\n",
    "\n",
    "        :param word: the successor that has been reached so far.\n",
    "        :param StepCount: the number of letters still to write.\n",
    "        :param GeodesicSuffixState: the state of word in the geodesic suffix machine.\n",
    "        :return: a list with repetition of all the HorocyclicWords word' as above.\n",
    "        '''\n",
    "        \n",
    "        if StepCount == 0:\n",
    "            return [word]\n",
    "\n",
    "        ResultingWords = []  \n",
    "        \n",
    "        for transition in self.geodesic_suffix_machine.transitions(GeodesicSuffixState):\n",
    "            #determine which subword transition.word_in should be inserted into.\n",
    "            if word.mode:\n",
    "                EarliestPossibleSubword = SubwordDictionary1234[transition.word_in]\n",
    "            else:\n",
    "                EarliestPossibleSubword = SubwordDictionary1256[transition.word_in]\n",
    "            \n",
    "            for i in reversed(range(EarliestPossibleSubword-1,4)):\n",
    "                #transition.word_in belongs in subword i either if it cannot commute to an earlier subword, or if subword i is the earliest subword the letter is allowed in.\n",
    "                if i == EarliestPossibleSubword-1 or (not fsm_gen.test_set_pair_commutation({transition.word_in},set(word[i]))):\n",
    "                    NewSubwordList = word.SubwordList\n",
    "                    NewSubword = self.word_gen.word(word[i])\n",
    "                    NewSubword.shortlex_append(transition.word_in)\n",
    "                    NewSubwordList[i] = NewSubword.word_as_list\n",
    "                    NewWord = self.word_gen.horocyclic_word(NewSubwordList, word.mode)\n",
    "                    break\n",
    "            ResultingWords.extend(self._geodesic_successor_horocyclic_suffixes(NewWord, StepCount-1, transition.to_state))\n",
    "            \n",
    "        return ResultingWords\n",
    "\n",
    "    def _switch_form_special_case(self, word:HorocyclicWord) -> HorocyclicWord:\n",
    "        '''\n",
    "        Given a horocyclic suffix of form 1234, return an equal horocyclic suffix of form 1256, or vice versa.\n",
    "        Only implemented in the case that subword 3 is empty\n",
    "        and that subword 4 consists of letters commuting with the ray letter that is between word_5 and word_6 if word is of form 1234, or vice versa.\n",
    "    \n",
    "        With this assumption, once a letter of word[4] is read that follows this ray letter, no letter preceding the ray letter can be written until a letter is written that does not commute with it\n",
    "        Therefore, the first time a letter of word[4] follows the relevant ray letter is the break between the resulting subwords.\n",
    "        This takes linear time to computer. Without the assumption, it would take quadratic time.\n",
    "    \n",
    "        :param word: A HorocyclicWord with empty third subword and subword 4 satisfying the condition above.\n",
    "        :return: An equivalent HorocyclicWord of the opposite form to that of word.\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        if word[3] != []:\n",
    "            raise ValueError('Not implemented in the general case')\n",
    "    \n",
    "        #We will need to insert a letter into the fourth subword of word.\n",
    "        #If word is of the form 1234, then the letter to be inserted is self.ray[0], and vice versa.\n",
    "        SplitLetter = self.ray[1-int(word.mode)]\n",
    "        \n",
    "        #sentinel value\n",
    "        SplitIndex = None\n",
    "        \n",
    "        for index in  range(0, len(word[4])):\n",
    "            if not word[4][index] in self.c_map[SplitLetter]:\n",
    "                raise ValueError('Not implemented in the general case')\n",
    "            if self.o_map[word[4][index]] > self.o_map[SplitLetter] and SplitIndex is None:\n",
    "                SplitIndex = index\n",
    "                \n",
    "        #At the end of either loop, SplitIndex records either the first instance of a letter commuting with and following SplitLetter\n",
    "        #Or, if each letter commutes with and precedes SplitLetter, then SplitIndex still has the sentinel value None.\n",
    "        if SplitIndex is None:\n",
    "            NewWord = self.word_gen.horocyclic_word([word[1], word[2], word[4], []], not word.mode)\n",
    "        else:\n",
    "            NewWord = self.word_gen.horocyclic_word([word[1], word[2], word[4][:SplitIndex:], word[4][SplitIndex::]], not word.mode)\n",
    "    \n",
    "        return NewWord\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "406c3a0d-80be-469c-a625-67629431e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Probably some kind of virtual theta graph? This one is guaranteed to have some non-terminal states, which is its point for debugging\n",
    "'''\n",
    "\n",
    "my_c_map = {\n",
    "    'a': {'b', 'g', 'h'}, 'b': {'a', 'z'}, 'c': {'d', 'e', 'g', 'z'}, 'd': {'c', 'e', 'f', 'z'},\n",
    "    'e': {'c', 'd', 'f', 'z'}, 'f': {'d', 'e', 'h', 'z'}, 'g': {'a', 'c'}, 'h': {'a', 'f'}, 'z': {'b', 'c', 'd', 'e', 'f'} \n",
    "}\n",
    "\n",
    "my_o_map = {\n",
    "    'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'z': 8\n",
    "}\n",
    "\n",
    "my_ray = ['a', 'z']\n",
    "\n",
    "\n",
    "\n",
    "#For the Sierpinski Carpet case:\n",
    "my_c_map = {\n",
    "    'a' : {'b', 'e', 'f', 'j'}, 'b' : {'a', 'c', 'f', 'g'},\n",
    "    'c' : {'b', 'd', 'g', 'h'}, 'd' : {'c', 'e', 'h', 'i'},\n",
    "    'e' : {'a', 'd', 'i', 'j'}, 'f' : {'a', 'b', 'g', 'j'},\n",
    "    'g' : {'b', 'c', 'f', 'h'}, 'h' : {'c', 'd', 'g', 'i'},\n",
    "    'i' : {'d', 'e', 'h', 'j'}, 'j' : {'a', 'e', 'f', 'i'}\n",
    "}\n",
    "\n",
    "my_o_map = {'a' : 0, 'b' : 1, 'c' : 2, 'd' : 3, 'e' : 4, 'f' : 5, 'g' : 6, 'h' : 7, 'i' : 8, 'j' : 9}\n",
    "my_ray = ['a', 'g']\n",
    "\n",
    "'''\n",
    "\n",
    "#For the virtual surface group case:\n",
    "\n",
    "my_c_map = {'a': {'b', 'e'}, 'b': {'a', 'c'}, 'c': {'b', 'd'}, 'd': {'e', 'c'}, 'e': {'a', 'd'}}\n",
    "my_o_map = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}\n",
    "my_ray = ['a', 'c']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b8fd37e-5e07-46ab-88ac-d32aa2dd5403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have requested the shortlex machine on an empty alphabet. Returning an automaton that accepts only the empty string\n",
      "You have requested the shortlex machine on an empty alphabet. Returning an automaton that accepts only the empty string\n",
      "You have requested the shortlex machine on an empty alphabet. Returning an automaton that accepts only the empty string\n",
      "Completed the uncancelable states. There are  2  of them.\n",
      "Completed the first batch of transitions. There are  30 transitions and  16  states in total\n",
      "Completed the nonterminal transitions. There are  70  transitions and  22  states in total\n",
      "completed the final transitions. There are  92 transitions and  17  final states in total\n",
      "Completed the uncancelable states. There are  2  of them.\n",
      "Completed the first batch of transitions. There are  30 transitions and  16  states in total\n",
      "Completed the nonterminal transitions. There are  70  transitions and  22  states in total\n",
      "completed the final transitions. There are  92 transitions and  17  final states in total\n",
      "Completed the uncancelable states. There are  2  of them.\n",
      "Completed the first batch of transitions. There are  30 transitions and  16  states in total\n",
      "Completed the nonterminal transitions. There are  70  transitions and  22  states in total\n",
      "completed the final transitions. There are  92 transitions and  17  final states in total\n"
     ]
    }
   ],
   "source": [
    "Object = DivergenceHorosphereGenerator(my_c_map, my_o_map, my_ray)\n",
    "FSMGenerator = Divergence_FSM_Generator(my_c_map, my_o_map, my_ray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21f83a9-e7be-4fdf-91bd-63c0f81a225c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffixes of length 3 calculated: \n",
      "\t\t 29 words found\n",
      "Processing pair  [] []\n",
      "The elongated word is  []  and the non-elongated word is  []\n",
      "The state of the elongated word is  (0, (0, ()))\n",
      "Its outgoing transitions are  [Transition from (0, (0, ())) to (0, (0, ('b',))): 'b'|-, Transition from (0, (0, ())) to (1, ((1, (('a', 'd', 'e'), ('a',))), ())): 'e'|-, Transition from (0, (0, ())) to (1, ((1, (('c', 'd'), ('c',))), ('c',))): 'd'|-]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mObject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhorosphere_as_networkx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 397\u001b[0m, in \u001b[0;36mDivergenceHorosphereGenerator.horosphere_as_networkx\u001b[0;34m(self, length, BusemannValue)\u001b[0m\n\u001b[1;32m    395\u001b[0m suffixes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_length_n_horocyclic_suffixes(length, \u001b[38;5;28mbool\u001b[39m(BusemannValue \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuffixes of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlength\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m calculated: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(suffixes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m words found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 397\u001b[0m edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_divergence_horosphere_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWords processing completed: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(suffixes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m words processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    400\u001b[0m G \u001b[38;5;241m=\u001b[39m networkx\u001b[38;5;241m.\u001b[39mGraph()\n",
      "Cell \u001b[0;32mIn[15], line 391\u001b[0m, in \u001b[0;36mDivergenceHorosphereGenerator.calculate_divergence_horosphere_edges\u001b[0;34m(self, HorocyclicSuffix_list)\u001b[0m\n\u001b[1;32m    388\u001b[0m edges \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m HorocyclicSuffix_list:\n\u001b[0;32m--> 391\u001b[0m     edges\u001b[38;5;241m.\u001b[39mappend( (\u001b[38;5;28mstr\u001b[39m(suffix), \u001b[38;5;28mstr\u001b[39m(newsuffix)) \u001b[38;5;28;01mfor\u001b[39;00m newsuffix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_divergence_adjacencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m )\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(edges)\n",
      "Cell \u001b[0;32mIn[15], line 374\u001b[0m, in \u001b[0;36mDivergenceHorosphereGenerator.calculate_divergence_adjacencies\u001b[0;34m(self, HorocyclicSuffix)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mUse \"calculate_same_length_divergence_adjacencies\" and \"calculate_shorter_divergence_adjacencies\" to find all adjacent words which are at most as long as suffix.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m:param HorocyclicSuffix: A horocyclic suffix.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m:return: All adjacent suffixes at most as long as \"suffix\".\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m adjacencies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 374\u001b[0m adjacencies\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_same_length_divergence_adjacencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHorocyclicSuffix\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    375\u001b[0m adjacencies\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_different_length_rips_adjacencies(HorocyclicSuffix))\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adjacencies\n",
      "Cell \u001b[0;32mIn[15], line 240\u001b[0m, in \u001b[0;36mDivergenceHorosphereGenerator.calculate_same_length_divergence_adjacencies\u001b[0;34m(self, HorocyclicSuffix)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe state of the elongated word is \u001b[39m\u001b[38;5;124m'\u001b[39m, ElongatedState\u001b[38;5;241m.\u001b[39mlabel())\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIts outgoing transitions are \u001b[39m\u001b[38;5;124m'\u001b[39m, relevant_suffix_machine\u001b[38;5;241m.\u001b[39mtransitions(ElongatedState))\n\u001b[0;32m--> 240\u001b[0m LettersAcceptedFromElongatedState \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mtransition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrelevant_suffix_machine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_transitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mElongatedState\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m#ElongatedTransitionDict = relevant_suffix_machine.transition_dict(ElongatedState)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m LettersAcceptedFromNonElongatedState \u001b[38;5;241m=\u001b[39m {transition\u001b[38;5;241m.\u001b[39mword_in \u001b[38;5;28;01mfor\u001b[39;00m transition \u001b[38;5;129;01min\u001b[39;00m relevant_suffix_machine\u001b[38;5;241m.\u001b[39miter_transitions(NonElongatedState)}\n",
      "Cell \u001b[0;32mIn[15], line 240\u001b[0m, in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe state of the elongated word is \u001b[39m\u001b[38;5;124m'\u001b[39m, ElongatedState\u001b[38;5;241m.\u001b[39mlabel())\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIts outgoing transitions are \u001b[39m\u001b[38;5;124m'\u001b[39m, relevant_suffix_machine\u001b[38;5;241m.\u001b[39mtransitions(ElongatedState))\n\u001b[0;32m--> 240\u001b[0m LettersAcceptedFromElongatedState \u001b[38;5;241m=\u001b[39m {transition\u001b[38;5;241m.\u001b[39mword_in \u001b[38;5;28;01mfor\u001b[39;00m transition \u001b[38;5;129;01min\u001b[39;00m relevant_suffix_machine\u001b[38;5;241m.\u001b[39miter_transitions(ElongatedState)}\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m#ElongatedTransitionDict = relevant_suffix_machine.transition_dict(ElongatedState)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m LettersAcceptedFromNonElongatedState \u001b[38;5;241m=\u001b[39m {transition\u001b[38;5;241m.\u001b[39mword_in \u001b[38;5;28;01mfor\u001b[39;00m transition \u001b[38;5;129;01min\u001b[39;00m relevant_suffix_machine\u001b[38;5;241m.\u001b[39miter_transitions(NonElongatedState)}\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "Object.horosphere_as_networkx(3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c811dd-b3b5-4630-8f4b-1828448b8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: Make sure that the part where I figure out which letters go in which subwords is correct. \n",
    "#Can there be letters which first appear in w_1 or w_2, but which cannot appear in w_3 (or w_4)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7118401-0a43-4484-9470-1fea10884f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have requested the shortlex machine on an empty alphabet. Returning an automaton that accepts only the empty string\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OddLengthGenerator = FSMGenerator.horocyclic_suffix_machine_1234()\n",
    "OddLengthGenerator.transitions(OddLengthGenerator.initial_states()[0])[1].word_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e72db6e7-9aff-4b5a-8191-d2a5a72f7a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c80cb-dfff-44ab-a05f-7f4427ab2110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
